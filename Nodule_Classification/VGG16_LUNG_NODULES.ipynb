{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe7fe23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as tnn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import splitfolders\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "import kornia\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from PIL import Image\n",
    "from pydicom import dcmread\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9d7cd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee286ad2",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41b970df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run gan_utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15c4011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_tensorboard(writer, loss, metric, tensorboard_step):\n",
    "    writer.add_scalar(metric, loss, global_step=tensorboard_step)\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "class EarlyStopping():\n",
    "    \"\"\"source: https://stackoverflow.com/questions/71998978/early-stopping-in-pytorch\"\"\"\n",
    "    def __init__(self, model, patience=5, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = -np.inf\n",
    "        self.model = model\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "            torch.save(self.model.state_dict(), 'models/vgg16.pkl')\n",
    "        elif validation_loss < self.min_validation_loss:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61f2d04",
   "metadata": {},
   "source": [
    "### Dataset and Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5996748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    min_val = MIN_HU_VALUE\n",
    "    max_val = MAX_HU_VALUE\n",
    "    image[image < min_val] = min_val\n",
    "    image[image > max_val] = max_val\n",
    "    image = (image - min_val) / (max_val - min_val)\n",
    "    return image\n",
    "\n",
    "class LungNoduleDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        images = os.listdir(image_dir)\n",
    "        if 'rtss.dcm' in images: images.remove('rtss.dcm')\n",
    "        self.images = images\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "         return len(self.images)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        hist_type_class = {'LUSC': 0 , 'LUAD': 1}\n",
    "        img_path = os.path.join(self.image_dir, self.images[index])\n",
    "        data = dcmread(img_path)\n",
    "        image = np.array(data.pixel_array).astype('float32')\n",
    "        # Conversio to HU\n",
    "        intercept = int(data.RescaleIntercept)\n",
    "        slope = int(data.RescaleSlope)\n",
    "        image = (slope * image) + intercept\n",
    "        image = normalize(image)\n",
    "        \n",
    "        label = img_path.split('/')[-1].split('_')[1]\n",
    "        label = torch.from_numpy(np.asarray(hist_type_class[label]))\n",
    "        \n",
    "#         label = 1 if img_path.split('/')[-1].split('_')[0] == 'GAN' else 0\n",
    "        \n",
    "        return self.transform(image), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce8c42ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(\n",
    "    train_dir,\n",
    "    val_dir,\n",
    "    test_dir,\n",
    "    train_transform,\n",
    "    test_transform,\n",
    "    n_samples=None\n",
    "):\n",
    "    train_dataset = LungNoduleDataset(image_dir=train_dir, transform=train_transform)\n",
    "    val_dataset = LungNoduleDataset(image_dir=val_dir, transform=test_transform)\n",
    "    test_dataset = LungNoduleDataset(image_dir=test_dir, transform=test_transform)\n",
    "    \n",
    "    # Samples n_samples data points from the training dataset\n",
    "    if n_samples:\n",
    "        len_dataset = len(train_dataset)\n",
    "        indices = list(range(len_dataset))\n",
    "        np.random.shuffle(indices)\n",
    "        train_dataset = Subset(train_dataset, indices[:n_samples])\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f834141",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharpenImage():\n",
    "    def __init__(self, kernel_size=(5,5), sigma=(2.5,2.5)):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def __call__(self, x): \n",
    "        x = kornia.utils.image_to_tensor(x, keepdim=False)\n",
    "        sharpen = kornia.filters.UnsharpMask(self.kernel_size, self.sigma)\n",
    "        sharpened_tensor = sharpen(x)\n",
    "        return sharpened_tensor[0][0].numpy()\n",
    "    \n",
    "class RandomRotationTransform:\n",
    "    \"\"\"Rotate by one of the given angles.\"\"\"\n",
    "\n",
    "    def __init__(self, angles):\n",
    "        self.angles = angles\n",
    "\n",
    "    def __call__(self, x):\n",
    "        angle = random.choice(self.angles)\n",
    "        return transforms.functional.rotate(x, angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba8f8968",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 5439\n",
      "Val dataset size: 679\n",
      "Test dataset size: 681\n",
      "Image Batch dimensions: torch.Size([32, 1, 64, 64])\n",
      "Image Label dimensions: torch.Size([32])\n",
      "Class labels of 5 examples: tensor([0, 1, 1, 1, 1])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMAGE_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "MIN_HU_VALUE = -1024\n",
    "MAX_HU_VALUE = 1000\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.5],\n",
    "                         std  = [0.5]),\n",
    "    ])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.5],\n",
    "                         std  = [0.5]),\n",
    "    ])\n",
    "\n",
    "\n",
    "#VGG16\n",
    "\"\"\"\n",
    "convolution + ReLU;\n",
    "max pooling;\n",
    "fully connected + ReLU;\n",
    "softmax;\n",
    "\n",
    "new dataset:\n",
    "/Storage/PauloOctavioDir/NSCLC-Radiomics/ \n",
    "\n",
    "old dataset:\n",
    "/Storage/PauloOctavioDir/Exames/\n",
    "\"\"\"\n",
    "\n",
    "# trainData = LungNoduleDataset(image_dir='/Storage/PauloOctavioDir/nodule_images/NSCLC/', transform=transform)\n",
    "# testData = LungNoduleDataset(image_dir='/Storage/PauloOctavioDir/nodule_images/HCRP/', transform=transform)\n",
    "\n",
    "train_dataset = LungNoduleDataset(image_dir='/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/train/images', transform=train_transform)\n",
    "val_dataset = LungNoduleDataset(image_dir='/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/val/images', transform=test_transform)\n",
    "test_dataset = LungNoduleDataset(image_dir='/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/test/images', transform=test_transform)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Val dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "train_loader, val_loader, test_loader = get_loaders(\n",
    "    train_dir = '/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/train/images',\n",
    "    val_dir = '/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/val/images',\n",
    "    test_dir = '/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/test/images',\n",
    "    train_transform = train_transform,\n",
    "    test_transform = test_transform,\n",
    ")\n",
    "\n",
    "# Checking the dataset \n",
    "for images, labels in train_loader:\n",
    "    print('Image Batch dimensions:', images.shape)\n",
    "    print('Image Label dimensions:', labels.shape)\n",
    "    print('Class labels of 5 examples:', labels[:5])\n",
    "    fig, ax = plt.subplots(1,5, figsize=(12,6))\n",
    "    for i, image in enumerate(images[:5]):\n",
    "        ax[i].imshow(image[0], vmin=-1, vmax=1)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63b0a965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Squamous': tensor(0.5575), 'Adenocarcinoma': tensor(0.4425)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_count = {'Squamous': 0 , 'Adenocarcinoma': 0}\n",
    "for _, label in train_loader:\n",
    "    label_count['Squamous'] += BATCH_SIZE - label.sum()\n",
    "    label_count['Adenocarcinoma'] += label.sum()\n",
    "total = sum(label_count.values())\n",
    "{k: v / total for k, v in label_count.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "012c0f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dataset_count():\n",
    "    dataset_count = {'HCRP': 0, 'NSCLC': 0, 'LPET': 0, 'GAN': 0}\n",
    "    for file in os.listdir('/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/train/images'):\n",
    "        dataset = file.split(\"_\")[0]\n",
    "        dataset_count[dataset] +=1\n",
    "    return dataset_count\n",
    "get_dataset_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9d001a",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e8f28dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(chann_in, chann_out, k_size, p_size):\n",
    "    layer = tnn.Sequential(\n",
    "        tnn.Conv2d(chann_in, chann_out, kernel_size=k_size, padding=p_size),\n",
    "        tnn.BatchNorm2d(chann_out),\n",
    "        tnn.ReLU()\n",
    "    )\n",
    "    return layer\n",
    "\n",
    "def vgg_conv_block(in_list, out_list, k_list, p_list, pooling_k, pooling_s):\n",
    "\n",
    "    layers = [ conv_layer(in_list[i], out_list[i], k_list[i], p_list[i]) for i in range(len(in_list)) ]\n",
    "    layers += [ tnn.MaxPool2d(kernel_size = pooling_k, stride = pooling_s)]\n",
    "    return tnn.Sequential(*layers)\n",
    "\n",
    "def vgg_fc_layer(size_in, size_out):\n",
    "    layer = tnn.Sequential(\n",
    "        tnn.Linear(size_in, size_out),\n",
    "        tnn.BatchNorm1d(size_out),\n",
    "        tnn.ReLU(),\n",
    "        tnn.Dropout(DROPOUT)\n",
    "    )\n",
    "    return layer\n",
    "\n",
    "class VGG16(tnn.Module):\n",
    "    def __init__(self, n_classes=1000):\n",
    "        super(VGG16, self).__init__()\n",
    "\n",
    "        # Conv blocks (BatchNorm + ReLU activation added in each block)\n",
    "        self.layer1 = vgg_conv_block([1,64], [64,64], [3,3], [1,1], 2, 2)\n",
    "        self.layer2 = vgg_conv_block([64,128], [128,128], [3,3], [1,1], 2, 2)\n",
    "        self.layer3 = vgg_conv_block([128,256,256], [256,256,256], [3,3,3], [1,1,1], 2, 2)\n",
    "        self.layer4 = vgg_conv_block([256,512,512], [512,512,512], [3,3,3], [1,1,1], 2, 2)\n",
    "        self.layer5 = vgg_conv_block([512,512,512], [512,512,512], [3,3,3], [1,1,1], 2, 2)\n",
    "\n",
    "        # FC layers\n",
    "        self.layer6 = vgg_fc_layer(2 * 2 * 512, 4096)\n",
    "        self.layer7 = vgg_fc_layer(4096, 4096)\n",
    "\n",
    "        # Final layer\n",
    "        self.layer8 = tnn.Linear(4096, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        vgg16_features = self.layer5(out)\n",
    "        out = vgg16_features.view(out.size(0), -1)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "\n",
    "        return vgg16_features, out\n",
    "    \n",
    "    def predict(self, x):\n",
    "        # a function to predict the labels of a batch of inputs\n",
    "        x = tnn.functional.softmax(self.forward(x, training=False))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9788a203",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32d7b8b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def train(train_loader, val_loader, overwritten_model_name=None, gan=None):\n",
    "    \n",
    "    # Model\n",
    "    vgg16 = VGG16(n_classes=N_CLASSES)\n",
    "    vgg16.cuda()\n",
    "    \n",
    "    # Loss, Optimizer & Scheduler\n",
    "    cost = tnn.CrossEntropyLoss()\n",
    "    if OPTIMIZER == 'SGD':\n",
    "        optimizer = torch.optim.SGD(vgg16.parameters(), lr=LEARNING_RATE, weight_decay = 0.0005, momentum = 0.9) \n",
    "    if OPTIMIZER == 'Adam':\n",
    "        optimizer = torch.optim.Adam(vgg16.parameters(), lr=LEARNING_RATE)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "    \n",
    "    dataset_count = get_dataset_count()\n",
    "    print(f\"Dataset distribution: {dataset_count}\")\n",
    "    if overwritten_model_name:\n",
    "        model_name = overwritten_model_name\n",
    "    else:\n",
    "        model_name = f\"{TENSORBOARD_MODEL_NAME}_{dataset_count['GAN']}_{gan}_s_{SEED}\"\n",
    "    writer = SummaryWriter(f\"logs/{model_name}\")\n",
    "    early_stopping = EarlyStopping(patience=15, min_delta=0.001, model=vgg16)\n",
    "    print('Starting model training...')\n",
    "    start = time.time()\n",
    "    for epoch in range(EPOCH):\n",
    "        avg_loss = 0\n",
    "        cnt = 0\n",
    "        batches = len(train_loader)\n",
    "        # Training\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()\n",
    "            _, outputs = vgg16(images)\n",
    "            loss = cost(outputs, labels)\n",
    "            avg_loss += loss.data\n",
    "            cnt += 1\n",
    "            if i % 500 == 0 and VERBOSE:\n",
    "                print(f\"[E: {epoch}] loss: {loss.data}, avg_loss: {avg_loss/cnt}\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        write_to_tensorboard(writer, loss.data, \"train/loss\", tensorboard_step= epoch + 1)\n",
    "        # Validation \n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            samples = 0\n",
    "            for _, (images, labels) in enumerate(val_loader):\n",
    "                images = images.cuda()\n",
    "                _, outputs = vgg16(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                correct += (predicted.cpu() == labels).sum()\n",
    "                samples += predicted.size(0)\n",
    "                acc = correct / samples\n",
    "            write_to_tensorboard(writer, acc, \"val/acc\", tensorboard_step= epoch + 1)\n",
    "        if OPTIMIZER == 'Adam':\n",
    "            scheduler.step(avg_loss / cnt)\n",
    "        if early_stopping.early_stop(acc):\n",
    "            break\n",
    "    end = time.time()\n",
    "    print('Finished model training!')\n",
    "    training_duration = str(datetime.timedelta(seconds= end - start))\n",
    "    print(f\"Trainig duration: {training_duration}\")\n",
    "    return model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6e6bd1",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff4e67ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "def test(test_loader, model_name, gan_model):\n",
    "    vgg16 = VGG16(n_classes=N_CLASSES)\n",
    "    vgg16.cuda()\n",
    "    vgg16.load_state_dict(torch.load('models/vgg16.pkl'))\n",
    "    vgg16.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        incorrect_examples_images = []\n",
    "        incorrect_examples_true_labels = []\n",
    "        for i, (images, labels) in enumerate(test_loader):\n",
    "            images = images.cuda()\n",
    "            _, outputs = vgg16(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted.cpu() == labels).sum()\n",
    "            incorret_mask = predicted.cpu() != labels\n",
    "            if len(images[incorret_mask]):\n",
    "                for image in images[incorret_mask]:\n",
    "                    incorrect_examples_images.append(image[0].cpu().numpy())\n",
    "                for label in labels[incorret_mask]:\n",
    "                    incorrect_examples_true_labels.append(label.cpu().numpy())\n",
    "            if i == 0:\n",
    "                preds = predicted.cpu().squeeze(-1).numpy()\n",
    "                target = labels.cpu().squeeze(-1).numpy()\n",
    "            else:\n",
    "                preds = np.concatenate([preds, predicted.cpu().squeeze(-1).numpy()])\n",
    "                target = np.concatenate([target, labels.cpu().squeeze(-1).numpy()])\n",
    "    print(f'Finished model {model_name} evaluation!')\n",
    "    cls_report_dict = classification_report(target, preds, digits=3, output_dict=True)\n",
    "    df_log = pd.read_csv('vgg16_logging.csv')\n",
    "    dataset_count = get_dataset_count()\n",
    "    metrics = [\n",
    "        model_name,\n",
    "        dataset_count['GAN'],\n",
    "        cls_report_dict['accuracy'],\n",
    "#         roc_auc_score(target, preds),\n",
    "        0,\n",
    "        cls_report_dict['macro avg']['precision'],\n",
    "        cls_report_dict['macro avg']['recall'],\n",
    "        cls_report_dict['macro avg']['f1-score'],\n",
    "        int(BATCH_SIZE),\n",
    "        LEARNING_RATE,\n",
    "        int(EPOCH),\n",
    "        OPTIMIZER,\n",
    "        DROPOUT,\n",
    "        int(SEED),\n",
    "        gan_model,\n",
    "    ]\n",
    "    df_log.loc[len(df_log)] = metrics\n",
    "    df_log.to_csv('vgg16_logging.csv', index=False)\n",
    "    print(f\"Test acc: {cls_report_dict['accuracy']} | Test f1-score: {cls_report_dict['macro avg']['f1-score']}\")\n",
    "    print('Saved testing logs.')\n",
    "    \n",
    "def plot_ROCAUC_curve(y_truth, y_proba, fig_size):\n",
    "    '''\n",
    "    Plots the Receiver Operating Characteristic Curve (ROC) and displays Area Under the Curve (AUC) score.\n",
    "    Args:\n",
    "        y_truth: ground truth for testing data output\n",
    "        y_proba: class probabilties predicted from model\n",
    "        fig_size: size of the output pyplot figure\n",
    "    Returns: void\n",
    "    '''\n",
    "\n",
    "    fpr, tpr, threshold = roc_curve(y_truth, y_proba)\n",
    "    auc_score = roc_auc_score(y_truth, y_proba)\n",
    "    txt_box = \"AUC Score: \" + str(round(auc_score, 4))\n",
    "    plt.figure(figsize=fig_size)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0, 1], [0, 1],'--')\n",
    "    plt.annotate(txt_box, xy=(0.65, 0.05), xycoords='axes fraction')\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "    plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a516f",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98572d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCH = 75\n",
    "N_CLASSES = 2\n",
    "DEVICE = torch.device('cuda:1' if torch.cuda.is_available else 'cpu')\n",
    "MIN_HU_VALUE = -1024\n",
    "MAX_HU_VALUE = 1000\n",
    "IMAGE_SIZE = 64\n",
    "TENSORBOARD_MODEL_NAME = 'vgg16_gan'\n",
    "VERBOSE = True\n",
    "OPTIMIZER = 'SGD'\n",
    "DROPOUT = .5\n",
    "SEED = 13\n",
    "TRAIN_DIR = '/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/train/images'\n",
    "VAL_DIR = '/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/val/images'\n",
    "TEST_DIR = '/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/test/images'\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# TRAIN_DIR = '/Storage/PauloOctavioDir/splitted_folders/gan_vs_real_adeno/train/gan_vs_real_adeno'\n",
    "# VAL_DIR = '/Storage/PauloOctavioDir/splitted_folders/gan_vs_real_adeno/val/gan_vs_real_adeno'\n",
    "# TEST_DIR = '/Storage/PauloOctavioDir/splitted_folders/gan_vs_real_adeno/test/gan_vs_real_adeno'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "551de80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_log = pd.DataFrame(\n",
    "#     columns=['model_name', 'no_gan_generated_images','avg_acc', 'auc', 'avg_precision', 'avg_recall', 'avg_f1-score'])\n",
    "# df_log.to_csv('vgg16_logging.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59dcd2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE_SIZE = 64\n",
    "# images_probs = {}\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToPILImage(),\n",
    "#     transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.RandomRotation(degrees = 90),\n",
    "#     transforms.RandomRotation(degrees = 180),\n",
    "#     transforms.RandomRotation(degrees = 270),\n",
    "#     transforms.GaussianBlur(3, sigma=3),\n",
    "#     transforms.RandomAdjustSharpness(sharpness_factor, p=0.5),\n",
    "#     transforms.Normalize(mean = [0.5],\n",
    "#                          std  = [0.5]),\n",
    "#     ])\n",
    "\n",
    "# vgg16 = VGG16(n_classes=N_CLASSES)\n",
    "# vgg16.cuda()\n",
    "# vgg16.load_state_dict(torch.load('models/vgg16.pkl'))\n",
    "# vgg16.eval()\n",
    "# gan_dir = '/Storage/PauloOctavioDir/gan_eval/gan_vs_real_adeno'\n",
    "# with torch.no_grad():\n",
    "#     for img_path in os.listdir(gan_dir):\n",
    "#         if img_path.startswith('GAN'):\n",
    "#             data = dcmread(gan_dir + img_path)\n",
    "#             image = np.array(data.pixel_array).astype('float32')\n",
    "#             image = transform(image)\n",
    "#             _, output = vgg16(image)\n",
    "#             prob = tnn.functional.softmax(output)\n",
    "#             images_probs[img_path] = prob[0]\n",
    "            \n",
    "# best_images = dict(sorted(images_probs.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fc986a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 0}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.86026531457901, avg_loss: 0.86026531457901\n",
      "[E: 1] loss: 0.6894057989120483, avg_loss: 0.6894057989120483\n",
      "[E: 2] loss: 1.0190683603286743, avg_loss: 1.0190683603286743\n",
      "[E: 3] loss: 1.2963334321975708, avg_loss: 1.2963334321975708\n",
      "[E: 4] loss: 0.3178514540195465, avg_loss: 0.3178514540195465\n",
      "[E: 5] loss: 0.2536715567111969, avg_loss: 0.2536715567111969\n",
      "[E: 6] loss: 0.2151365727186203, avg_loss: 0.2151365727186203\n",
      "[E: 7] loss: 0.1340058445930481, avg_loss: 0.1340058445930481\n",
      "[E: 8] loss: 0.26030847430229187, avg_loss: 0.26030847430229187\n",
      "[E: 9] loss: 0.06734580546617508, avg_loss: 0.06734580546617508\n",
      "[E: 10] loss: 0.14740264415740967, avg_loss: 0.14740264415740967\n",
      "[E: 11] loss: 0.02768835984170437, avg_loss: 0.02768835984170437\n",
      "[E: 12] loss: 0.08520285785198212, avg_loss: 0.08520285785198212\n",
      "[E: 13] loss: 0.019149357452988625, avg_loss: 0.019149357452988625\n",
      "[E: 14] loss: 0.08505313843488693, avg_loss: 0.08505313843488693\n",
      "[E: 15] loss: 0.14758911728858948, avg_loss: 0.14758911728858948\n",
      "[E: 16] loss: 0.19098569452762604, avg_loss: 0.19098569452762604\n",
      "[E: 17] loss: 0.0026035404298454523, avg_loss: 0.0026035404298454523\n",
      "[E: 18] loss: 0.02185237593948841, avg_loss: 0.02185237593948841\n",
      "[E: 19] loss: 0.0017094105714932084, avg_loss: 0.0017094105714932084\n",
      "[E: 20] loss: 0.024424554780125618, avg_loss: 0.024424554780125618\n",
      "[E: 21] loss: 0.0028868597000837326, avg_loss: 0.0028868597000837326\n",
      "[E: 22] loss: 0.043979667127132416, avg_loss: 0.043979667127132416\n",
      "[E: 23] loss: 0.0009488103678449988, avg_loss: 0.0009488103678449988\n",
      "[E: 24] loss: 0.0005539480480365455, avg_loss: 0.0005539480480365455\n",
      "[E: 25] loss: 0.022348133847117424, avg_loss: 0.022348133847117424\n",
      "[E: 26] loss: 0.11512930691242218, avg_loss: 0.11512930691242218\n",
      "[E: 27] loss: 0.003262832062318921, avg_loss: 0.003262832062318921\n",
      "[E: 28] loss: 0.01702222414314747, avg_loss: 0.01702222414314747\n",
      "[E: 29] loss: 0.0009840416023507714, avg_loss: 0.0009840416023507714\n",
      "[E: 30] loss: 0.0004930228460580111, avg_loss: 0.0004930228460580111\n",
      "[E: 31] loss: 0.04971025139093399, avg_loss: 0.04971025139093399\n",
      "[E: 32] loss: 0.07381550967693329, avg_loss: 0.07381550967693329\n",
      "[E: 33] loss: 0.0014037935761734843, avg_loss: 0.0014037935761734843\n",
      "[E: 34] loss: 0.0033085313625633717, avg_loss: 0.0033085313625633717\n",
      "[E: 35] loss: 0.007481284439563751, avg_loss: 0.007481284439563751\n",
      "[E: 36] loss: 0.00017463362019043416, avg_loss: 0.00017463362019043416\n",
      "[E: 37] loss: 0.0004103505634702742, avg_loss: 0.0004103505634702742\n",
      "[E: 38] loss: 0.0002446743019390851, avg_loss: 0.0002446743019390851\n",
      "[E: 39] loss: 0.007471592165529728, avg_loss: 0.007471592165529728\n",
      "[E: 40] loss: 0.000582177541218698, avg_loss: 0.000582177541218698\n",
      "[E: 41] loss: 0.010053092613816261, avg_loss: 0.010053092613816261\n",
      "[E: 42] loss: 0.00015983168850652874, avg_loss: 0.00015983168850652874\n",
      "[E: 43] loss: 0.00026819095364771783, avg_loss: 0.00026819095364771783\n",
      "Finished model training!\n",
      "Trainig duration: 0:28:47.859733\n",
      "Finished model vgg16_gan_only_real_images_s_42 evaluation!\n",
      "Test acc: 0.9122023809523809\n",
      "Saved testing logs.\n"
     ]
    }
   ],
   "source": [
    "# Modelo Treinado apenas com iamgens reais\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.5],\n",
    "                         std  = [0.5]),\n",
    "    ])\n",
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "delete_gan_images()\n",
    "train_loader, val_loader, test_loader = get_loaders(\n",
    "    train_dir = TRAIN_DIR,\n",
    "    val_dir = VAL_DIR,\n",
    "    test_dir = TEST_DIR,\n",
    "    train_transform = transform,\n",
    "    test_transform = transform,\n",
    ")\n",
    "gan_model = 'no_gan'\n",
    "overwritten_model_name = f\"{TENSORBOARD_MODEL_NAME}_only_real_images_s_{SEED}\"\n",
    "model_name = train(train_loader, val_loader, overwritten_model_name=overwritten_model_name)\n",
    "test(test_loader, model_name, gan_model=gan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15fb5b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Model: generator_pggan_roi_adeno_epochs_50_alpha_0.75_aug_rot_blur_sharp.pth.tar\n",
      "Finished model test_vgg16_trained_on_real_imgs_classifying_gan_imgs_s_42 evaluation!\n",
      "Test acc: 0.6213662790697675 | Test f1-score: 0.619232756894507\n",
      "Saved testing logs.\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Model: generator_pggan_roi_adeno_all_data.pth.tar\n",
      "Finished model test_vgg16_trained_on_real_imgs_classifying_gan_imgs_s_42 evaluation!\n",
      "Test acc: 0.7122093023255814 | Test f1-score: 0.7119896486765909\n",
      "Saved testing logs.\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Model: generator_pggan_roi_adeno_epochs_75_lr_0.001.pth.tar\n",
      "Finished model test_vgg16_trained_on_real_imgs_classifying_gan_imgs_s_42 evaluation!\n",
      "Test acc: 0.6257267441860465 | Test f1-score: 0.6256221448431913\n",
      "Saved testing logs.\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Model: generator_pggan_roi_adeno_epochs_30_30_50_50_75_alpha_0.75_bs_32_32_32_32_32_affn_trns_only.pth.tar\n",
      "Finished model test_vgg16_trained_on_real_imgs_classifying_gan_imgs_s_42 evaluation!\n",
      "Test acc: 0.7143895348837209 | Test f1-score: 0.7138985898831138\n",
      "Saved testing logs.\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'generator_pggan_roi_adeno_epochs_30_30_50_50_75_alpha_0.75_bs_64_64_64_32_32_affn_trns_only.pth.tar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4b2545ca673e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m         gen_squamous, no_gan_images // 2, 'LUSC', \"/Storage/PauloOctavioDir/gan_eval/vgg16_real_imgs\")\n\u001b[1;32m     51\u001b[0m     generate_images(\n\u001b[0;32m---> 52\u001b[0;31m         gen_adeno, no_gan_images // 2, 'LUAD', \"/Storage/PauloOctavioDir/gan_eval/vgg16_real_imgs\")\n\u001b[0m\u001b[1;32m     53\u001b[0m     train_loader, val_loader, test_loader = get_loaders(\n\u001b[1;32m     54\u001b[0m         \u001b[0mtrain_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTRAIN_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-93030dce46f0>\u001b[0m in \u001b[0;36mgenerate_images\u001b[0;34m(gen_checkpoint, n, hist_type, path, alpha, step, z_dim, device, learning_rate, in_channels, channels_img)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mopt_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6c76d13f4ece>\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(checkpoint_file, model, optimizer, lr)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=> Loading checkpoint\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"optimizer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PauloLucas/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PauloLucas/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PauloLucas/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'generator_pggan_roi_adeno_epochs_30_30_50_50_75_alpha_0.75_bs_64_64_64_32_32_affn_trns_only.pth.tar'"
     ]
    }
   ],
   "source": [
    "# Validao do modelo treinado apenas com imagens reais usando apenas imagens da GAN\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.5],\n",
    "                         std  = [0.5]),\n",
    "    ])\n",
    "SEED = 42\n",
    "no_gan_images = 1400\n",
    "\n",
    "scc_list = [\n",
    "    f'generator_pggan_roi_squamous_epochs_50_alpha_0.75_aug_rot_blur_sharp.pth.tar',\n",
    "    f'generator_pggan_roi_squamous_all_data.pth.tar', \n",
    "    f'generator_pggan_roi_squamous_epochs_75_lr_0.001.pth.tar',\n",
    "    f'generator_pggan_roi_squamous_epochs_30_30_50_50_75_alpha_0.75_bs_32_32_32_32_32_affn_trns_only.pth.tar',\n",
    "    f'generator_pggan_roi_squamous_epochs_30_30_50_50_75_alpha_0.75_bs_64_64_64_32_32_affn_trns_only.pth.tar'\n",
    "]\n",
    "\n",
    "adc_list = [\n",
    "    f'generator_pggan_roi_adeno_epochs_50_alpha_0.75_aug_rot_blur_sharp.pth.tar',\n",
    "    f'generator_pggan_roi_adeno_all_data.pth.tar', \n",
    "    f'generator_pggan_roi_adeno_epochs_75_lr_0.001.pth.tar',\n",
    "    f'generator_pggan_roi_adeno_epochs_30_30_50_50_75_alpha_0.75_bs_32_32_32_32_32_affn_trns_only.pth.tar',\n",
    "    f'generator_pggan_roi_adeno_epochs_30_30_50_50_75_alpha_0.75_bs_64_64_64_32_32_affn_trns_only.pth.tar'\n",
    "]\n",
    "# hist_type = 'adeno'\n",
    "# adc_list = [\n",
    "#     f'generator_pggan_roi_{hist_type}_epochs_30_alpha_0.75_bs_64_64_64_32_32_affn_trns_only.pth.tar',\n",
    "#     f'generator_pggan_roi_{hist_type}_epochs_75_alpha_0.75_bs_64_64_64_32_32_affn_trns_only.pth.tar',\n",
    "#     f'generator_pggan_roi_{hist_type}_epochs_50_alpha_0.75_bs_64_64_64_32_32_affn_trns_only.pth.tar',\n",
    "#     f'generator_pggan_roi_{hist_type}_epochs_30_30_50_50_75_alpha_0.75_bs_32_32_32_32_32_affn_trns_only.pth.tar',\n",
    "#     f'generator_pggan_roi_{hist_type}_epochs_30_30_50_50_50_alpha_0.75_bs_32_32_32_32_32_affn_trns_only.pth.tar',\n",
    "#     f'generator_pggan_roi_{hist_type}_epochs_30_alpha_0.75_bs_32_32_32_32_32_affn_trns_only.pth.tar',\n",
    "#     f'generator_pggan_roi_{hist_type}_epochs_50_alpha_0.75_bs_32_32_32_32_32_affn_trns_only.pth.tar',\n",
    "#     f'generator_pggan_roi_{hist_type}_epochs_75_alpha_0.75_bs_32_32_32_32_32_affn_trns_only.pth.tar',\n",
    "#     f'generator_pggan_roi_{hist_type}_epochs_50_alpha_0.75_aug_rot_blur_sharp.pth.tar',\n",
    "#     f'generator_pggan_roi_{hist_type}_all_data.pth.tar', \n",
    "#     f'generator_pggan_roi_{hist_type}_epochs_75_lr_0.001.pth.tar',\n",
    "# ]\n",
    "\n",
    "\n",
    "for gen_adeno, gen_squamous in zip(adc_list, scc_list):\n",
    "# for gen_adeno in adc_list:\n",
    "    directory = '/Storage/PauloOctavioDir/gan_eval/vgg16_real_imgs/'\n",
    "    for file in os.listdir(directory):\n",
    "            os.remove(os.path.join(directory, file))\n",
    "    generate_images(\n",
    "        gen_squamous, no_gan_images // 2, 'LUSC', \"/Storage/PauloOctavioDir/gan_eval/vgg16_real_imgs\")\n",
    "    generate_images(\n",
    "        gen_adeno, no_gan_images // 2, 'LUAD', \"/Storage/PauloOctavioDir/gan_eval/vgg16_real_imgs\")\n",
    "    train_loader, val_loader, test_loader = get_loaders(\n",
    "        train_dir = TRAIN_DIR,\n",
    "        val_dir = VAL_DIR,\n",
    "        test_dir = '/Storage/PauloOctavioDir/gan_eval/vgg16_real_imgs',\n",
    "        train_transform = transform,\n",
    "        test_transform = transform,\n",
    "    )\n",
    "    print(f'Model: {gen_adeno}')\n",
    "    gan_model = gen_adeno\n",
    "    model_name = f'test_vgg16_trained_on_real_imgs_classifying_gan_imgs_s_{SEED}'\n",
    "    test(test_loader, model_name, gan_model=gan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f677159",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 GAN images:\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 0}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.9058138132095337, avg_loss: 0.9058138132095337\n",
      "[E: 1] loss: 0.6920968890190125, avg_loss: 0.6920968890190125\n",
      "[E: 2] loss: 0.8057072162628174, avg_loss: 0.8057072162628174\n",
      "[E: 3] loss: 1.611696481704712, avg_loss: 1.611696481704712\n",
      "[E: 4] loss: 1.3430839776992798, avg_loss: 1.3430839776992798\n",
      "[E: 5] loss: 0.837726354598999, avg_loss: 0.837726354598999\n",
      "[E: 6] loss: 0.492527037858963, avg_loss: 0.492527037858963\n",
      "[E: 7] loss: 0.9208222031593323, avg_loss: 0.9208222031593323\n",
      "[E: 8] loss: 0.5225419402122498, avg_loss: 0.5225419402122498\n",
      "[E: 9] loss: 0.723551332950592, avg_loss: 0.723551332950592\n",
      "[E: 10] loss: 0.7505784630775452, avg_loss: 0.7505784630775452\n",
      "[E: 11] loss: 0.5143197774887085, avg_loss: 0.5143197774887085\n",
      "[E: 12] loss: 0.3873656690120697, avg_loss: 0.3873656690120697\n",
      "[E: 13] loss: 1.4416784048080444, avg_loss: 1.4416784048080444\n",
      "[E: 14] loss: 1.6196565628051758, avg_loss: 1.6196565628051758\n",
      "[E: 15] loss: 0.5221096277236938, avg_loss: 0.5221096277236938\n",
      "[E: 16] loss: 0.590855598449707, avg_loss: 0.590855598449707\n",
      "[E: 17] loss: 0.6772286891937256, avg_loss: 0.6772286891937256\n",
      "[E: 18] loss: 0.4832744598388672, avg_loss: 0.4832744598388672\n",
      "[E: 19] loss: 0.758065938949585, avg_loss: 0.758065938949585\n",
      "[E: 20] loss: 0.499408483505249, avg_loss: 0.499408483505249\n",
      "[E: 21] loss: 0.5112326145172119, avg_loss: 0.5112326145172119\n",
      "[E: 22] loss: 0.4712597131729126, avg_loss: 0.4712597131729126\n",
      "[E: 23] loss: 0.31042763590812683, avg_loss: 0.31042763590812683\n",
      "[E: 24] loss: 0.9017654657363892, avg_loss: 0.9017654657363892\n",
      "[E: 25] loss: 1.5750892162322998, avg_loss: 1.5750892162322998\n",
      "[E: 26] loss: 0.3289540112018585, avg_loss: 0.3289540112018585\n",
      "[E: 27] loss: 0.43614351749420166, avg_loss: 0.43614351749420166\n",
      "[E: 28] loss: 0.5392659306526184, avg_loss: 0.5392659306526184\n",
      "[E: 29] loss: 0.24032555520534515, avg_loss: 0.24032555520534515\n",
      "[E: 30] loss: 0.35884997248649597, avg_loss: 0.35884997248649597\n",
      "[E: 31] loss: 0.4151064455509186, avg_loss: 0.4151064455509186\n",
      "[E: 32] loss: 0.15418864786624908, avg_loss: 0.15418864786624908\n",
      "[E: 33] loss: 0.23356260359287262, avg_loss: 0.23356260359287262\n",
      "[E: 34] loss: 0.21475623548030853, avg_loss: 0.21475623548030853\n",
      "[E: 35] loss: 0.22149471938610077, avg_loss: 0.22149471938610077\n",
      "[E: 36] loss: 0.1359798014163971, avg_loss: 0.1359798014163971\n",
      "[E: 37] loss: 0.31086957454681396, avg_loss: 0.31086957454681396\n",
      "[E: 38] loss: 0.12967528402805328, avg_loss: 0.12967528402805328\n",
      "[E: 39] loss: 0.19284099340438843, avg_loss: 0.19284099340438843\n",
      "[E: 40] loss: 0.15658576786518097, avg_loss: 0.15658576786518097\n",
      "[E: 41] loss: 0.17163912951946259, avg_loss: 0.17163912951946259\n",
      "[E: 42] loss: 0.41966792941093445, avg_loss: 0.41966792941093445\n",
      "[E: 43] loss: 0.28740790486335754, avg_loss: 0.28740790486335754\n",
      "[E: 44] loss: 0.22802332043647766, avg_loss: 0.22802332043647766\n",
      "[E: 45] loss: 0.7342721819877625, avg_loss: 0.7342721819877625\n",
      "[E: 46] loss: 0.3270968198776245, avg_loss: 0.3270968198776245\n",
      "[E: 47] loss: 0.03527218848466873, avg_loss: 0.03527218848466873\n",
      "[E: 48] loss: 0.13562792539596558, avg_loss: 0.13562792539596558\n",
      "[E: 49] loss: 0.2144499123096466, avg_loss: 0.2144499123096466\n",
      "[E: 50] loss: 0.10866327583789825, avg_loss: 0.10866327583789825\n",
      "[E: 51] loss: 0.16390451788902283, avg_loss: 0.16390451788902283\n",
      "[E: 52] loss: 0.141984224319458, avg_loss: 0.141984224319458\n",
      "[E: 53] loss: 0.10501953959465027, avg_loss: 0.10501953959465027\n",
      "[E: 54] loss: 0.19399189949035645, avg_loss: 0.19399189949035645\n",
      "[E: 55] loss: 0.019158732146024704, avg_loss: 0.019158732146024704\n",
      "[E: 56] loss: 0.21901965141296387, avg_loss: 0.21901965141296387\n",
      "[E: 57] loss: 0.21445882320404053, avg_loss: 0.21445882320404053\n",
      "[E: 58] loss: 0.09250488877296448, avg_loss: 0.09250488877296448\n",
      "[E: 59] loss: 0.049058426171541214, avg_loss: 0.049058426171541214\n",
      "[E: 60] loss: 0.02020096965134144, avg_loss: 0.02020096965134144\n",
      "[E: 61] loss: 0.05761034041643143, avg_loss: 0.05761034041643143\n",
      "[E: 62] loss: 0.023180454969406128, avg_loss: 0.023180454969406128\n",
      "[E: 63] loss: 0.0714639201760292, avg_loss: 0.0714639201760292\n",
      "[E: 64] loss: 0.05593189224600792, avg_loss: 0.05593189224600792\n",
      "[E: 65] loss: 0.05073405057191849, avg_loss: 0.05073405057191849\n",
      "[E: 66] loss: 0.042490676045417786, avg_loss: 0.042490676045417786\n",
      "[E: 67] loss: 0.06865040957927704, avg_loss: 0.06865040957927704\n",
      "Finished model training!\n",
      "Trainig duration: 0:42:31.723413\n",
      "Finished model vgg16_gan_augmented_rot_.2_flip_.2_0_old_gan_s_42 evaluation!\n",
      "Test acc: 0.8943452380952381\n",
      "Saved testing logs.\n",
      "1000 GAN images:\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 1000}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.8454132676124573, avg_loss: 0.8454132676124573\n",
      "[E: 1] loss: 0.8959587216377258, avg_loss: 0.8959587216377258\n",
      "[E: 2] loss: 0.7450023293495178, avg_loss: 0.7450023293495178\n",
      "[E: 3] loss: 0.7347009778022766, avg_loss: 0.7347009778022766\n",
      "[E: 4] loss: 0.5876328349113464, avg_loss: 0.5876328349113464\n",
      "[E: 5] loss: 0.579218327999115, avg_loss: 0.579218327999115\n",
      "[E: 6] loss: 1.7460895776748657, avg_loss: 1.7460895776748657\n",
      "[E: 7] loss: 0.6514652371406555, avg_loss: 0.6514652371406555\n",
      "[E: 8] loss: 0.5344613790512085, avg_loss: 0.5344613790512085\n",
      "[E: 9] loss: 0.4851945638656616, avg_loss: 0.4851945638656616\n",
      "[E: 10] loss: 0.6926109194755554, avg_loss: 0.6926109194755554\n",
      "[E: 11] loss: 1.1071163415908813, avg_loss: 1.1071163415908813\n",
      "[E: 12] loss: 0.9111273884773254, avg_loss: 0.9111273884773254\n",
      "[E: 13] loss: 0.7460817694664001, avg_loss: 0.7460817694664001\n",
      "[E: 14] loss: 0.42878079414367676, avg_loss: 0.42878079414367676\n",
      "[E: 15] loss: 0.5572717785835266, avg_loss: 0.5572717785835266\n",
      "[E: 16] loss: 0.5856541395187378, avg_loss: 0.5856541395187378\n",
      "[E: 17] loss: 0.48803719878196716, avg_loss: 0.48803719878196716\n",
      "[E: 18] loss: 0.3232609033584595, avg_loss: 0.3232609033584595\n",
      "[E: 19] loss: 0.43550342321395874, avg_loss: 0.43550342321395874\n",
      "[E: 20] loss: 0.5024268627166748, avg_loss: 0.5024268627166748\n",
      "[E: 21] loss: 0.5725911259651184, avg_loss: 0.5725911259651184\n",
      "[E: 22] loss: 0.5947896838188171, avg_loss: 0.5947896838188171\n",
      "[E: 23] loss: 0.47706422209739685, avg_loss: 0.47706422209739685\n",
      "[E: 24] loss: 0.5913256406784058, avg_loss: 0.5913256406784058\n",
      "[E: 25] loss: 1.2606581449508667, avg_loss: 1.2606581449508667\n",
      "[E: 26] loss: 0.4846709668636322, avg_loss: 0.4846709668636322\n",
      "[E: 27] loss: 0.41468751430511475, avg_loss: 0.41468751430511475\n",
      "[E: 28] loss: 0.22697043418884277, avg_loss: 0.22697043418884277\n",
      "[E: 29] loss: 0.45235228538513184, avg_loss: 0.45235228538513184\n",
      "[E: 30] loss: 0.8851651549339294, avg_loss: 0.8851651549339294\n",
      "[E: 31] loss: 0.23817022144794464, avg_loss: 0.23817022144794464\n",
      "[E: 32] loss: 0.1725936383008957, avg_loss: 0.1725936383008957\n",
      "[E: 33] loss: 0.4408527910709381, avg_loss: 0.4408527910709381\n",
      "[E: 34] loss: 0.10932325571775436, avg_loss: 0.10932325571775436\n",
      "[E: 35] loss: 0.31870460510253906, avg_loss: 0.31870460510253906\n",
      "[E: 36] loss: 0.3467068374156952, avg_loss: 0.3467068374156952\n",
      "[E: 37] loss: 0.23356860876083374, avg_loss: 0.23356860876083374\n",
      "[E: 38] loss: 0.17805448174476624, avg_loss: 0.17805448174476624\n",
      "[E: 39] loss: 0.3217143714427948, avg_loss: 0.3217143714427948\n",
      "[E: 40] loss: 0.0672273337841034, avg_loss: 0.0672273337841034\n",
      "[E: 41] loss: 0.28958460688591003, avg_loss: 0.28958460688591003\n",
      "[E: 42] loss: 0.11926627159118652, avg_loss: 0.11926627159118652\n",
      "[E: 43] loss: 0.1763421595096588, avg_loss: 0.1763421595096588\n",
      "[E: 44] loss: 0.168958842754364, avg_loss: 0.168958842754364\n",
      "[E: 45] loss: 0.1512349247932434, avg_loss: 0.1512349247932434\n",
      "[E: 46] loss: 0.06581881642341614, avg_loss: 0.06581881642341614\n",
      "[E: 47] loss: 0.026335712522268295, avg_loss: 0.026335712522268295\n",
      "[E: 48] loss: 0.09037059545516968, avg_loss: 0.09037059545516968\n",
      "[E: 49] loss: 0.19238756597042084, avg_loss: 0.19238756597042084\n",
      "[E: 50] loss: 0.08814600855112076, avg_loss: 0.08814600855112076\n",
      "[E: 51] loss: 0.03293096274137497, avg_loss: 0.03293096274137497\n",
      "[E: 52] loss: 0.06485608965158463, avg_loss: 0.06485608965158463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E: 53] loss: 0.19626326858997345, avg_loss: 0.19626326858997345\n",
      "Finished model training!\n",
      "Trainig duration: 0:41:41.545223\n",
      "Finished model vgg16_gan_augmented_rot_.2_flip_.2_1000_old_gan_s_42 evaluation!\n",
      "Test acc: 0.8928571428571429\n",
      "Saved testing logs.\n",
      "2000 GAN images:\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 2000}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.8612524271011353, avg_loss: 0.8612524271011353\n",
      "[E: 1] loss: 0.7224250435829163, avg_loss: 0.7224250435829163\n",
      "[E: 2] loss: 0.7187500596046448, avg_loss: 0.7187500596046448\n",
      "[E: 3] loss: 0.913865864276886, avg_loss: 0.913865864276886\n",
      "[E: 4] loss: 0.4695960283279419, avg_loss: 0.4695960283279419\n",
      "[E: 5] loss: 1.0054901838302612, avg_loss: 1.0054901838302612\n",
      "[E: 6] loss: 0.8005192875862122, avg_loss: 0.8005192875862122\n",
      "[E: 7] loss: 0.6370477676391602, avg_loss: 0.6370477676391602\n",
      "[E: 8] loss: 1.0177712440490723, avg_loss: 1.0177712440490723\n",
      "[E: 9] loss: 0.8023319244384766, avg_loss: 0.8023319244384766\n",
      "[E: 10] loss: 0.5825619697570801, avg_loss: 0.5825619697570801\n",
      "[E: 11] loss: 0.47043341398239136, avg_loss: 0.47043341398239136\n",
      "[E: 12] loss: 0.30816635489463806, avg_loss: 0.30816635489463806\n",
      "[E: 13] loss: 0.7465144991874695, avg_loss: 0.7465144991874695\n",
      "[E: 14] loss: 0.4489666521549225, avg_loss: 0.4489666521549225\n",
      "[E: 15] loss: 0.4316454529762268, avg_loss: 0.4316454529762268\n",
      "[E: 16] loss: 0.4840300679206848, avg_loss: 0.4840300679206848\n",
      "[E: 17] loss: 0.35490289330482483, avg_loss: 0.35490289330482483\n",
      "[E: 18] loss: 0.35875555872917175, avg_loss: 0.35875555872917175\n",
      "[E: 19] loss: 0.41768449544906616, avg_loss: 0.41768449544906616\n",
      "[E: 20] loss: 0.33950355648994446, avg_loss: 0.33950355648994446\n",
      "[E: 21] loss: 0.21508169174194336, avg_loss: 0.21508169174194336\n",
      "[E: 22] loss: 0.4432303309440613, avg_loss: 0.4432303309440613\n",
      "[E: 23] loss: 0.11186221987009048, avg_loss: 0.11186221987009048\n",
      "[E: 24] loss: 0.22092236578464508, avg_loss: 0.22092236578464508\n",
      "[E: 25] loss: 0.2526903450489044, avg_loss: 0.2526903450489044\n",
      "[E: 26] loss: 0.41674113273620605, avg_loss: 0.41674113273620605\n",
      "[E: 27] loss: 0.14392997324466705, avg_loss: 0.14392997324466705\n",
      "[E: 28] loss: 0.121115542948246, avg_loss: 0.121115542948246\n",
      "[E: 29] loss: 0.12498239427804947, avg_loss: 0.12498239427804947\n",
      "[E: 30] loss: 0.2431614100933075, avg_loss: 0.2431614100933075\n",
      "[E: 31] loss: 0.0904776081442833, avg_loss: 0.0904776081442833\n",
      "[E: 32] loss: 0.13301622867584229, avg_loss: 0.13301622867584229\n",
      "[E: 33] loss: 0.10911843180656433, avg_loss: 0.10911843180656433\n",
      "[E: 34] loss: 0.08015454560518265, avg_loss: 0.08015454560518265\n",
      "[E: 35] loss: 0.04283751919865608, avg_loss: 0.04283751919865608\n",
      "[E: 36] loss: 0.149989515542984, avg_loss: 0.149989515542984\n",
      "[E: 37] loss: 0.020833473652601242, avg_loss: 0.020833473652601242\n",
      "[E: 38] loss: 0.09430080652236938, avg_loss: 0.09430080652236938\n",
      "[E: 39] loss: 0.19874411821365356, avg_loss: 0.19874411821365356\n",
      "[E: 40] loss: 0.16401930153369904, avg_loss: 0.16401930153369904\n",
      "[E: 41] loss: 0.0274045430123806, avg_loss: 0.0274045430123806\n",
      "[E: 42] loss: 0.0801161453127861, avg_loss: 0.0801161453127861\n",
      "[E: 43] loss: 0.08258567750453949, avg_loss: 0.08258567750453949\n",
      "[E: 44] loss: 0.4542306661605835, avg_loss: 0.4542306661605835\n",
      "[E: 45] loss: 0.15030230581760406, avg_loss: 0.15030230581760406\n",
      "[E: 46] loss: 0.07753495126962662, avg_loss: 0.07753495126962662\n",
      "[E: 47] loss: 0.04785407334566116, avg_loss: 0.04785407334566116\n",
      "[E: 48] loss: 0.00917419046163559, avg_loss: 0.00917419046163559\n",
      "[E: 49] loss: 0.062469907104969025, avg_loss: 0.062469907104969025\n",
      "[E: 50] loss: 0.025588683784008026, avg_loss: 0.025588683784008026\n",
      "[E: 51] loss: 0.058928947895765305, avg_loss: 0.058928947895765305\n",
      "[E: 52] loss: 0.05270904675126076, avg_loss: 0.05270904675126076\n",
      "[E: 53] loss: 0.059911154210567474, avg_loss: 0.059911154210567474\n",
      "[E: 54] loss: 0.10400186479091644, avg_loss: 0.10400186479091644\n",
      "[E: 55] loss: 0.018548984080553055, avg_loss: 0.018548984080553055\n",
      "[E: 56] loss: 0.03198299929499626, avg_loss: 0.03198299929499626\n",
      "[E: 57] loss: 0.050689946860075, avg_loss: 0.050689946860075\n",
      "Finished model training!\n",
      "Trainig duration: 0:51:12.336124\n",
      "Finished model vgg16_gan_augmented_rot_.2_flip_.2_2000_old_gan_s_42 evaluation!\n",
      "Test acc: 0.8928571428571429\n",
      "Saved testing logs.\n",
      "3000 GAN images:\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 3000}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.7945911288261414, avg_loss: 0.7945911288261414\n",
      "[E: 1] loss: 0.9379428029060364, avg_loss: 0.9379428029060364\n",
      "[E: 2] loss: 0.7434658408164978, avg_loss: 0.7434658408164978\n",
      "[E: 3] loss: 0.6081008911132812, avg_loss: 0.6081008911132812\n",
      "[E: 4] loss: 0.8980799317359924, avg_loss: 0.8980799317359924\n",
      "[E: 5] loss: 0.691093921661377, avg_loss: 0.691093921661377\n",
      "[E: 6] loss: 0.6508899927139282, avg_loss: 0.6508899927139282\n",
      "[E: 7] loss: 0.47378119826316833, avg_loss: 0.47378119826316833\n",
      "[E: 8] loss: 0.30196940898895264, avg_loss: 0.30196940898895264\n",
      "[E: 9] loss: 0.6013216972351074, avg_loss: 0.6013216972351074\n",
      "[E: 10] loss: 0.33675920963287354, avg_loss: 0.33675920963287354\n",
      "[E: 11] loss: 0.26382941007614136, avg_loss: 0.26382941007614136\n",
      "[E: 12] loss: 0.2917579114437103, avg_loss: 0.2917579114437103\n",
      "[E: 13] loss: 0.3615071475505829, avg_loss: 0.3615071475505829\n",
      "[E: 14] loss: 0.22260308265686035, avg_loss: 0.22260308265686035\n",
      "[E: 15] loss: 0.23232713341712952, avg_loss: 0.23232713341712952\n",
      "[E: 16] loss: 0.4023487865924835, avg_loss: 0.4023487865924835\n",
      "[E: 17] loss: 0.33958983421325684, avg_loss: 0.33958983421325684\n",
      "[E: 18] loss: 0.36622166633605957, avg_loss: 0.36622166633605957\n",
      "[E: 19] loss: 0.3122711479663849, avg_loss: 0.3122711479663849\n",
      "[E: 20] loss: 0.16785947978496552, avg_loss: 0.16785947978496552\n",
      "[E: 21] loss: 0.18232063949108124, avg_loss: 0.18232063949108124\n",
      "[E: 22] loss: 0.27992042899131775, avg_loss: 0.27992042899131775\n",
      "[E: 23] loss: 0.3067624866962433, avg_loss: 0.3067624866962433\n",
      "[E: 24] loss: 0.25433555245399475, avg_loss: 0.25433555245399475\n",
      "[E: 25] loss: 0.23894014954566956, avg_loss: 0.23894014954566956\n",
      "[E: 26] loss: 0.145502507686615, avg_loss: 0.145502507686615\n",
      "[E: 27] loss: 0.09859581291675568, avg_loss: 0.09859581291675568\n",
      "[E: 28] loss: 0.03400450199842453, avg_loss: 0.03400450199842453\n",
      "[E: 29] loss: 0.10213180631399155, avg_loss: 0.10213180631399155\n",
      "[E: 30] loss: 0.11174163222312927, avg_loss: 0.11174163222312927\n",
      "[E: 31] loss: 0.1729801893234253, avg_loss: 0.1729801893234253\n",
      "[E: 32] loss: 0.15161289274692535, avg_loss: 0.15161289274692535\n",
      "[E: 33] loss: 0.07257912307977676, avg_loss: 0.07257912307977676\n",
      "[E: 34] loss: 0.028600914403796196, avg_loss: 0.028600914403796196\n",
      "[E: 35] loss: 0.024264216423034668, avg_loss: 0.024264216423034668\n",
      "[E: 36] loss: 0.07988761365413666, avg_loss: 0.07988761365413666\n",
      "[E: 37] loss: 0.10592671483755112, avg_loss: 0.10592671483755112\n",
      "[E: 38] loss: 0.1805618554353714, avg_loss: 0.1805618554353714\n",
      "[E: 39] loss: 0.017553234472870827, avg_loss: 0.017553234472870827\n",
      "[E: 40] loss: 0.07118208706378937, avg_loss: 0.07118208706378937\n",
      "[E: 41] loss: 0.011200259439647198, avg_loss: 0.011200259439647198\n",
      "[E: 42] loss: 0.15299399197101593, avg_loss: 0.15299399197101593\n",
      "[E: 43] loss: 0.018025388941168785, avg_loss: 0.018025388941168785\n",
      "[E: 44] loss: 0.0318826287984848, avg_loss: 0.0318826287984848\n",
      "[E: 45] loss: 0.06795559823513031, avg_loss: 0.06795559823513031\n",
      "[E: 46] loss: 0.024479100480675697, avg_loss: 0.024479100480675697\n",
      "[E: 47] loss: 0.019489731639623642, avg_loss: 0.019489731639623642\n",
      "[E: 48] loss: 0.18587735295295715, avg_loss: 0.18587735295295715\n",
      "[E: 49] loss: 0.016382385045289993, avg_loss: 0.016382385045289993\n",
      "[E: 50] loss: 0.1607951521873474, avg_loss: 0.1607951521873474\n",
      "[E: 51] loss: 0.16329561173915863, avg_loss: 0.16329561173915863\n",
      "[E: 52] loss: 0.08523418754339218, avg_loss: 0.08523418754339218\n",
      "[E: 53] loss: 0.10865490883588791, avg_loss: 0.10865490883588791\n",
      "[E: 54] loss: 0.09492979943752289, avg_loss: 0.09492979943752289\n",
      "Finished model training!\n",
      "Trainig duration: 0:54:32.139275\n",
      "Finished model vgg16_gan_augmented_rot_.2_flip_.2_3000_old_gan_s_42 evaluation!\n",
      "Test acc: 0.9122023809523809\n",
      "Saved testing logs.\n",
      "4000 GAN images:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 4000}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.7297548055648804, avg_loss: 0.7297548055648804\n",
      "[E: 1] loss: 0.6682664155960083, avg_loss: 0.6682664155960083\n",
      "[E: 2] loss: 0.445983350276947, avg_loss: 0.445983350276947\n",
      "[E: 3] loss: 0.4087845981121063, avg_loss: 0.4087845981121063\n",
      "[E: 4] loss: 0.516315758228302, avg_loss: 0.516315758228302\n",
      "[E: 5] loss: 0.4454565942287445, avg_loss: 0.4454565942287445\n",
      "[E: 6] loss: 0.1903967261314392, avg_loss: 0.1903967261314392\n",
      "[E: 7] loss: 0.5186139345169067, avg_loss: 0.5186139345169067\n",
      "[E: 8] loss: 0.19738702476024628, avg_loss: 0.19738702476024628\n",
      "[E: 9] loss: 0.1825411319732666, avg_loss: 0.1825411319732666\n",
      "[E: 10] loss: 0.22915643453598022, avg_loss: 0.22915643453598022\n",
      "[E: 11] loss: 0.08745978772640228, avg_loss: 0.08745978772640228\n",
      "[E: 12] loss: 0.17052975296974182, avg_loss: 0.17052975296974182\n",
      "[E: 13] loss: 0.1438826322555542, avg_loss: 0.1438826322555542\n",
      "[E: 14] loss: 0.2889799475669861, avg_loss: 0.2889799475669861\n",
      "[E: 15] loss: 0.08955971896648407, avg_loss: 0.08955971896648407\n",
      "[E: 16] loss: 0.43234488368034363, avg_loss: 0.43234488368034363\n",
      "[E: 17] loss: 0.053557734936475754, avg_loss: 0.053557734936475754\n",
      "[E: 18] loss: 0.17829804122447968, avg_loss: 0.17829804122447968\n",
      "[E: 19] loss: 0.07936371862888336, avg_loss: 0.07936371862888336\n",
      "[E: 20] loss: 0.4180191159248352, avg_loss: 0.4180191159248352\n",
      "[E: 21] loss: 0.05822066590189934, avg_loss: 0.05822066590189934\n",
      "[E: 22] loss: 0.22901540994644165, avg_loss: 0.22901540994644165\n",
      "[E: 23] loss: 0.12647710740566254, avg_loss: 0.12647710740566254\n",
      "[E: 24] loss: 0.09068133682012558, avg_loss: 0.09068133682012558\n",
      "[E: 25] loss: 0.09890969842672348, avg_loss: 0.09890969842672348\n",
      "[E: 26] loss: 0.19108328223228455, avg_loss: 0.19108328223228455\n",
      "[E: 27] loss: 0.3660374581813812, avg_loss: 0.3660374581813812\n",
      "[E: 28] loss: 0.07842399179935455, avg_loss: 0.07842399179935455\n",
      "[E: 29] loss: 0.2090957909822464, avg_loss: 0.2090957909822464\n",
      "[E: 30] loss: 0.05102509260177612, avg_loss: 0.05102509260177612\n",
      "[E: 31] loss: 0.2012782245874405, avg_loss: 0.2012782245874405\n",
      "[E: 32] loss: 0.03494783490896225, avg_loss: 0.03494783490896225\n",
      "[E: 33] loss: 0.012861542403697968, avg_loss: 0.012861542403697968\n",
      "[E: 34] loss: 0.09518176317214966, avg_loss: 0.09518176317214966\n",
      "[E: 35] loss: 0.025733688846230507, avg_loss: 0.025733688846230507\n",
      "[E: 36] loss: 0.03372008353471756, avg_loss: 0.03372008353471756\n",
      "[E: 37] loss: 0.027199139818549156, avg_loss: 0.027199139818549156\n",
      "[E: 38] loss: 0.0630226731300354, avg_loss: 0.0630226731300354\n",
      "[E: 39] loss: 0.07520751655101776, avg_loss: 0.07520751655101776\n",
      "[E: 40] loss: 0.17731575667858124, avg_loss: 0.17731575667858124\n",
      "[E: 41] loss: 0.09729181230068207, avg_loss: 0.09729181230068207\n",
      "[E: 42] loss: 0.07218636572360992, avg_loss: 0.07218636572360992\n",
      "[E: 43] loss: 0.07224621623754501, avg_loss: 0.07224621623754501\n",
      "[E: 44] loss: 0.08543814718723297, avg_loss: 0.08543814718723297\n",
      "[E: 45] loss: 0.025500023737549782, avg_loss: 0.025500023737549782\n",
      "[E: 46] loss: 0.03469862788915634, avg_loss: 0.03469862788915634\n",
      "[E: 47] loss: 0.021603886038064957, avg_loss: 0.021603886038064957\n",
      "Finished model training!\n",
      "Trainig duration: 0:53:05.954830\n",
      "Finished model vgg16_gan_augmented_rot_.2_flip_.2_4000_old_gan_s_42 evaluation!\n",
      "Test acc: 0.8958333333333334\n",
      "Saved testing logs.\n",
      "5000 GAN images:\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 5000}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.6894997954368591, avg_loss: 0.6894997954368591\n",
      "[E: 1] loss: 0.5375556945800781, avg_loss: 0.5375556945800781\n",
      "[E: 2] loss: 0.5742476582527161, avg_loss: 0.5742476582527161\n",
      "[E: 3] loss: 0.3439362049102783, avg_loss: 0.3439362049102783\n",
      "[E: 4] loss: 0.5131270289421082, avg_loss: 0.5131270289421082\n",
      "[E: 5] loss: 0.3643297553062439, avg_loss: 0.3643297553062439\n",
      "[E: 6] loss: 0.22178319096565247, avg_loss: 0.22178319096565247\n",
      "[E: 7] loss: 0.3116326332092285, avg_loss: 0.3116326332092285\n",
      "[E: 8] loss: 0.21495772898197174, avg_loss: 0.21495772898197174\n",
      "[E: 9] loss: 0.13440018892288208, avg_loss: 0.13440018892288208\n",
      "[E: 10] loss: 0.09416507929563522, avg_loss: 0.09416507929563522\n",
      "[E: 11] loss: 0.1885686069726944, avg_loss: 0.1885686069726944\n",
      "[E: 12] loss: 0.22101591527462006, avg_loss: 0.22101591527462006\n",
      "[E: 13] loss: 0.0773589015007019, avg_loss: 0.0773589015007019\n",
      "[E: 14] loss: 0.20199769735336304, avg_loss: 0.20199769735336304\n",
      "[E: 15] loss: 0.15716330707073212, avg_loss: 0.15716330707073212\n",
      "[E: 16] loss: 0.1338111311197281, avg_loss: 0.1338111311197281\n",
      "[E: 17] loss: 0.09578680992126465, avg_loss: 0.09578680992126465\n",
      "[E: 18] loss: 0.23473718762397766, avg_loss: 0.23473718762397766\n",
      "[E: 19] loss: 0.35412833094596863, avg_loss: 0.35412833094596863\n",
      "[E: 20] loss: 0.1263812780380249, avg_loss: 0.1263812780380249\n",
      "[E: 21] loss: 0.11888188868761063, avg_loss: 0.11888188868761063\n",
      "[E: 22] loss: 0.11010794341564178, avg_loss: 0.11010794341564178\n",
      "[E: 23] loss: 0.0757623091340065, avg_loss: 0.0757623091340065\n",
      "[E: 24] loss: 0.08132001757621765, avg_loss: 0.08132001757621765\n",
      "[E: 25] loss: 0.04513264447450638, avg_loss: 0.04513264447450638\n",
      "[E: 26] loss: 0.08372078090906143, avg_loss: 0.08372078090906143\n",
      "[E: 27] loss: 0.0657755509018898, avg_loss: 0.0657755509018898\n",
      "[E: 28] loss: 0.2241736501455307, avg_loss: 0.2241736501455307\n",
      "[E: 29] loss: 0.05688495188951492, avg_loss: 0.05688495188951492\n",
      "[E: 30] loss: 0.009540499188005924, avg_loss: 0.009540499188005924\n",
      "[E: 31] loss: 0.03411558270454407, avg_loss: 0.03411558270454407\n",
      "[E: 32] loss: 0.045427579432725906, avg_loss: 0.045427579432725906\n",
      "[E: 33] loss: 0.018814796581864357, avg_loss: 0.018814796581864357\n",
      "[E: 34] loss: 0.09843576699495316, avg_loss: 0.09843576699495316\n",
      "[E: 35] loss: 0.025729119777679443, avg_loss: 0.025729119777679443\n",
      "[E: 36] loss: 0.02176043950021267, avg_loss: 0.02176043950021267\n",
      "[E: 37] loss: 0.028780316933989525, avg_loss: 0.028780316933989525\n",
      "[E: 38] loss: 0.05203256756067276, avg_loss: 0.05203256756067276\n",
      "[E: 39] loss: 0.026430798694491386, avg_loss: 0.026430798694491386\n",
      "[E: 40] loss: 0.13555532693862915, avg_loss: 0.13555532693862915\n",
      "[E: 41] loss: 0.03838740289211273, avg_loss: 0.03838740289211273\n",
      "[E: 42] loss: 0.08828345686197281, avg_loss: 0.08828345686197281\n",
      "[E: 43] loss: 0.01474431436508894, avg_loss: 0.01474431436508894\n",
      "[E: 44] loss: 0.014940816909074783, avg_loss: 0.014940816909074783\n",
      "[E: 45] loss: 0.038141731172800064, avg_loss: 0.038141731172800064\n",
      "[E: 46] loss: 0.1803777664899826, avg_loss: 0.1803777664899826\n",
      "[E: 47] loss: 0.0053584338165819645, avg_loss: 0.0053584338165819645\n",
      "[E: 48] loss: 0.003284663427621126, avg_loss: 0.003284663427621126\n",
      "[E: 49] loss: 0.011125127784907818, avg_loss: 0.011125127784907818\n",
      "Finished model training!\n",
      "Trainig duration: 1:00:49.542005\n",
      "Finished model vgg16_gan_augmented_rot_.2_flip_.2_5000_old_gan_s_42 evaluation!\n",
      "Test acc: 0.8720238095238095\n",
      "Saved testing logs.\n"
     ]
    }
   ],
   "source": [
    "aug_transform = transforms.Compose([\n",
    "#     transforms.RandomApply([SharpenImage()], p=.3),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=.2),\n",
    "#     transforms.RandomApply([transforms.GaussianBlur(kernel_size=3, sigma=(1,2))], p=.3),\n",
    "    RandomRotationTransform(angles=[90,270, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.5],\n",
    "                         std  = [0.5]),\n",
    "])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.5],\n",
    "                         std  = [0.5]),\n",
    "    ])\n",
    "\n",
    "gen_adeno = \"generator_pggan_roi_adeno_all_data.pth.tar\"\n",
    "gen_squamous = \"generator_pggan_roi_squamous_all_data.pth.tar\"\n",
    "for SEED in [42]:\n",
    "    for no_gan_images in [0, 1000, 2000, 3000, 4000, 5000]:\n",
    "        seed_everything(SEED)\n",
    "        print(f\"{no_gan_images} GAN images:\")\n",
    "        delete_gan_images()\n",
    "        generate_images(\n",
    "            gen_squamous, no_gan_images // 2, 'LUSC', \"/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/train/images/\")\n",
    "        generate_images(\n",
    "            gen_adeno, no_gan_images // 2, 'LUAD', \"/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/train/images/\")\n",
    "        train_loader, val_loader, test_loader = get_loaders(\n",
    "            train_dir = TRAIN_DIR,\n",
    "            val_dir = VAL_DIR,\n",
    "            test_dir = TEST_DIR,\n",
    "            train_transform = aug_transform,\n",
    "            test_transform = transform,\n",
    "        )\n",
    "        gan_model = 'old_gan'\n",
    "        overwritten_model_name = f\"{TENSORBOARD_MODEL_NAME}_augmented_rot_.2_flip_.2_{no_gan_images}_{gan_model}_s_{SEED}\"\n",
    "        model_name = train(train_loader, val_loader, overwritten_model_name=overwritten_model_name)\n",
    "        test(test_loader, model_name, gan_model=gan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9d9070e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 GAN images:\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 0}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.7926419973373413, avg_loss: 0.7926419973373413\n",
      "[E: 1] loss: 0.6666727662086487, avg_loss: 0.6666727662086487\n",
      "[E: 2] loss: 0.7884994745254517, avg_loss: 0.7884994745254517\n",
      "[E: 3] loss: 1.0589654445648193, avg_loss: 1.0589654445648193\n",
      "[E: 4] loss: 0.5936004519462585, avg_loss: 0.5936004519462585\n",
      "[E: 5] loss: 0.36558207869529724, avg_loss: 0.36558207869529724\n",
      "[E: 6] loss: 0.9656534194946289, avg_loss: 0.9656534194946289\n",
      "[E: 7] loss: 0.2394169569015503, avg_loss: 0.2394169569015503\n",
      "[E: 8] loss: 0.1767488420009613, avg_loss: 0.1767488420009613\n",
      "[E: 9] loss: 0.3446007966995239, avg_loss: 0.3446007966995239\n",
      "[E: 10] loss: 0.05813752859830856, avg_loss: 0.05813752859830856\n",
      "[E: 11] loss: 0.09075944125652313, avg_loss: 0.09075944125652313\n",
      "[E: 12] loss: 0.026701096445322037, avg_loss: 0.026701096445322037\n",
      "[E: 13] loss: 0.0043936921283602715, avg_loss: 0.0043936921283602715\n",
      "[E: 14] loss: 0.02282700501382351, avg_loss: 0.02282700501382351\n",
      "[E: 15] loss: 0.009229821152985096, avg_loss: 0.009229821152985096\n",
      "[E: 16] loss: 0.0036917822435498238, avg_loss: 0.0036917822435498238\n",
      "[E: 17] loss: 0.04179835319519043, avg_loss: 0.04179835319519043\n",
      "[E: 18] loss: 0.005716127809137106, avg_loss: 0.005716127809137106\n",
      "[E: 19] loss: 0.047406453639268875, avg_loss: 0.047406453639268875\n",
      "[E: 20] loss: 0.0014854175969958305, avg_loss: 0.0014854175969958305\n",
      "[E: 21] loss: 0.26815149188041687, avg_loss: 0.26815149188041687\n",
      "[E: 22] loss: 0.008523334749042988, avg_loss: 0.008523334749042988\n",
      "[E: 23] loss: 0.015591881237924099, avg_loss: 0.015591881237924099\n",
      "[E: 24] loss: 0.0028734717052429914, avg_loss: 0.0028734717052429914\n",
      "[E: 25] loss: 0.0008076181984506547, avg_loss: 0.0008076181984506547\n",
      "[E: 26] loss: 0.0038314892444759607, avg_loss: 0.0038314892444759607\n",
      "[E: 27] loss: 0.09004662930965424, avg_loss: 0.09004662930965424\n",
      "[E: 28] loss: 0.012910176999866962, avg_loss: 0.012910176999866962\n",
      "[E: 29] loss: 0.0013798376312479377, avg_loss: 0.0013798376312479377\n",
      "[E: 30] loss: 0.0020822156220674515, avg_loss: 0.0020822156220674515\n",
      "[E: 31] loss: 0.01790437661111355, avg_loss: 0.01790437661111355\n",
      "[E: 32] loss: 0.0007682190625928342, avg_loss: 0.0007682190625928342\n",
      "[E: 33] loss: 9.691351442597806e-05, avg_loss: 9.691351442597806e-05\n",
      "[E: 34] loss: 0.007525227963924408, avg_loss: 0.007525227963924408\n",
      "[E: 35] loss: 0.00015823663852643222, avg_loss: 0.00015823663852643222\n",
      "[E: 36] loss: 0.002241434995085001, avg_loss: 0.002241434995085001\n",
      "[E: 37] loss: 0.00026785203954204917, avg_loss: 0.00026785203954204917\n",
      "[E: 38] loss: 0.00028079230105504394, avg_loss: 0.00028079230105504394\n",
      "[E: 39] loss: 0.001130784279666841, avg_loss: 0.001130784279666841\n",
      "[E: 40] loss: 6.312596815405414e-05, avg_loss: 6.312596815405414e-05\n",
      "[E: 41] loss: 0.006449999753385782, avg_loss: 0.006449999753385782\n",
      "[E: 42] loss: 0.0017683723708614707, avg_loss: 0.0017683723708614707\n",
      "[E: 43] loss: 0.02530915103852749, avg_loss: 0.02530915103852749\n",
      "[E: 44] loss: 0.0012548983795568347, avg_loss: 0.0012548983795568347\n",
      "[E: 45] loss: 0.1274852603673935, avg_loss: 0.1274852603673935\n",
      "[E: 46] loss: 0.0006229481659829617, avg_loss: 0.0006229481659829617\n",
      "[E: 47] loss: 0.0008293395512737334, avg_loss: 0.0008293395512737334\n",
      "[E: 48] loss: 0.006353868171572685, avg_loss: 0.006353868171572685\n",
      "[E: 49] loss: 0.0006249915459193289, avg_loss: 0.0006249915459193289\n",
      "[E: 50] loss: 0.001730108866468072, avg_loss: 0.001730108866468072\n",
      "[E: 51] loss: 0.0025366353802382946, avg_loss: 0.0025366353802382946\n",
      "[E: 52] loss: 0.00011485581489978358, avg_loss: 0.00011485581489978358\n",
      "[E: 53] loss: 5.6210737966466695e-05, avg_loss: 5.6210737966466695e-05\n",
      "[E: 54] loss: 0.00013303771265782416, avg_loss: 0.00013303771265782416\n",
      "[E: 55] loss: 2.5621160602895543e-05, avg_loss: 2.5621160602895543e-05\n",
      "Finished model training!\n",
      "Trainig duration: 0:36:19.059849\n",
      "Finished model vgg16_gan_augmented_sharp_blur_0_old_gan_s_42 evaluation!\n",
      "Test acc: 0.9002976190476191\n",
      "Saved testing logs.\n",
      "1000 GAN images:\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 1000}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.7402121424674988, avg_loss: 0.7402121424674988\n",
      "[E: 1] loss: 0.7451049089431763, avg_loss: 0.7451049089431763\n",
      "[E: 2] loss: 0.9463459849357605, avg_loss: 0.9463459849357605\n",
      "[E: 3] loss: 0.7365521192550659, avg_loss: 0.7365521192550659\n",
      "[E: 4] loss: 0.6774797439575195, avg_loss: 0.6774797439575195\n",
      "[E: 5] loss: 0.4179084002971649, avg_loss: 0.4179084002971649\n",
      "[E: 6] loss: 0.21392595767974854, avg_loss: 0.21392595767974854\n",
      "[E: 7] loss: 0.266474187374115, avg_loss: 0.266474187374115\n",
      "[E: 8] loss: 0.10740330070257187, avg_loss: 0.10740330070257187\n",
      "[E: 9] loss: 0.35240912437438965, avg_loss: 0.35240912437438965\n",
      "[E: 10] loss: 0.050893548876047134, avg_loss: 0.050893548876047134\n",
      "[E: 11] loss: 0.1410570740699768, avg_loss: 0.1410570740699768\n",
      "[E: 12] loss: 0.05472079664468765, avg_loss: 0.05472079664468765\n",
      "[E: 13] loss: 0.015547659248113632, avg_loss: 0.015547659248113632\n",
      "[E: 14] loss: 0.0033264528028666973, avg_loss: 0.0033264528028666973\n",
      "[E: 15] loss: 0.014757595956325531, avg_loss: 0.014757595956325531\n",
      "[E: 16] loss: 0.04626421257853508, avg_loss: 0.04626421257853508\n",
      "[E: 17] loss: 0.03331524878740311, avg_loss: 0.03331524878740311\n",
      "[E: 18] loss: 0.001227043685503304, avg_loss: 0.001227043685503304\n",
      "[E: 19] loss: 0.015675071626901627, avg_loss: 0.015675071626901627\n",
      "[E: 20] loss: 0.004965153057128191, avg_loss: 0.004965153057128191\n",
      "[E: 21] loss: 0.08291440457105637, avg_loss: 0.08291440457105637\n",
      "[E: 22] loss: 0.0019997821655124426, avg_loss: 0.0019997821655124426\n",
      "[E: 23] loss: 0.017584457993507385, avg_loss: 0.017584457993507385\n",
      "[E: 24] loss: 0.002745384816080332, avg_loss: 0.002745384816080332\n",
      "[E: 25] loss: 0.023036759346723557, avg_loss: 0.023036759346723557\n",
      "[E: 26] loss: 0.0021327075082808733, avg_loss: 0.0021327075082808733\n",
      "[E: 27] loss: 0.00033752742456272244, avg_loss: 0.00033752742456272244\n",
      "[E: 28] loss: 0.0005235477001406252, avg_loss: 0.0005235477001406252\n",
      "[E: 29] loss: 0.0002019355451921001, avg_loss: 0.0002019355451921001\n",
      "[E: 30] loss: 0.003545981366187334, avg_loss: 0.003545981366187334\n",
      "[E: 31] loss: 0.000509698293171823, avg_loss: 0.000509698293171823\n",
      "[E: 32] loss: 0.0014060813700780272, avg_loss: 0.0014060813700780272\n",
      "[E: 33] loss: 0.00014411065785679966, avg_loss: 0.00014411065785679966\n",
      "[E: 34] loss: 0.006880640983581543, avg_loss: 0.006880640983581543\n",
      "[E: 35] loss: 0.005664551164954901, avg_loss: 0.005664551164954901\n",
      "[E: 36] loss: 0.00014606238983105868, avg_loss: 0.00014606238983105868\n",
      "[E: 37] loss: 0.0001987863943213597, avg_loss: 0.0001987863943213597\n",
      "[E: 38] loss: 0.004669831600040197, avg_loss: 0.004669831600040197\n",
      "[E: 39] loss: 0.003970392979681492, avg_loss: 0.003970392979681492\n",
      "[E: 40] loss: 0.032283131033182144, avg_loss: 0.032283131033182144\n",
      "[E: 41] loss: 0.05300483480095863, avg_loss: 0.05300483480095863\n",
      "[E: 42] loss: 0.0005425004637800157, avg_loss: 0.0005425004637800157\n",
      "[E: 43] loss: 0.004875693004578352, avg_loss: 0.004875693004578352\n",
      "[E: 44] loss: 0.0018618678441271186, avg_loss: 0.0018618678441271186\n",
      "[E: 45] loss: 6.99426673236303e-05, avg_loss: 6.99426673236303e-05\n",
      "[E: 46] loss: 0.0031758605036884546, avg_loss: 0.0031758605036884546\n",
      "[E: 47] loss: 0.03065594658255577, avg_loss: 0.03065594658255577\n",
      "[E: 48] loss: 1.4717336853209417e-05, avg_loss: 1.4717336853209417e-05\n",
      "[E: 49] loss: 0.00011011661263182759, avg_loss: 0.00011011661263182759\n",
      "[E: 50] loss: 0.00032807354000397027, avg_loss: 0.00032807354000397027\n",
      "[E: 51] loss: 0.1518445611000061, avg_loss: 0.1518445611000061\n",
      "[E: 52] loss: 0.16151906549930573, avg_loss: 0.16151906549930573\n",
      "[E: 53] loss: 0.0007096475455909967, avg_loss: 0.0007096475455909967\n",
      "[E: 54] loss: 0.0601363331079483, avg_loss: 0.0601363331079483\n",
      "[E: 55] loss: 0.007564119528979063, avg_loss: 0.007564119528979063\n",
      "[E: 56] loss: 0.10738039761781693, avg_loss: 0.10738039761781693\n",
      "[E: 57] loss: 0.0003296807990409434, avg_loss: 0.0003296807990409434\n",
      "[E: 58] loss: 0.0005681870388798416, avg_loss: 0.0005681870388798416\n",
      "Finished model training!\n",
      "Trainig duration: 0:45:00.712993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished model vgg16_gan_augmented_sharp_blur_1000_old_gan_s_42 evaluation!\n",
      "Test acc: 0.9107142857142857\n",
      "Saved testing logs.\n",
      "2000 GAN images:\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 2000}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.8582926988601685, avg_loss: 0.8582926988601685\n",
      "[E: 1] loss: 0.8964390754699707, avg_loss: 0.8964390754699707\n",
      "[E: 2] loss: 1.0839194059371948, avg_loss: 1.0839194059371948\n",
      "[E: 3] loss: 0.39971259236335754, avg_loss: 0.39971259236335754\n",
      "[E: 4] loss: 0.39023563265800476, avg_loss: 0.39023563265800476\n",
      "[E: 5] loss: 0.21277333796024323, avg_loss: 0.21277333796024323\n",
      "[E: 6] loss: 0.391241192817688, avg_loss: 0.391241192817688\n",
      "[E: 7] loss: 0.1930381953716278, avg_loss: 0.1930381953716278\n",
      "[E: 8] loss: 0.10241967439651489, avg_loss: 0.10241967439651489\n",
      "[E: 9] loss: 0.19426938891410828, avg_loss: 0.19426938891410828\n",
      "[E: 10] loss: 0.11032810807228088, avg_loss: 0.11032810807228088\n",
      "[E: 11] loss: 0.1076953336596489, avg_loss: 0.1076953336596489\n",
      "[E: 12] loss: 0.044820431619882584, avg_loss: 0.044820431619882584\n",
      "[E: 13] loss: 0.038067471235990524, avg_loss: 0.038067471235990524\n",
      "[E: 14] loss: 0.08759805560112, avg_loss: 0.08759805560112\n",
      "[E: 15] loss: 0.002251602476462722, avg_loss: 0.002251602476462722\n",
      "[E: 16] loss: 0.0004981593228876591, avg_loss: 0.0004981593228876591\n",
      "[E: 17] loss: 0.0660347044467926, avg_loss: 0.0660347044467926\n",
      "[E: 18] loss: 0.12155525386333466, avg_loss: 0.12155525386333466\n",
      "[E: 19] loss: 0.0017180253053084016, avg_loss: 0.0017180253053084016\n",
      "[E: 20] loss: 0.008317342959344387, avg_loss: 0.008317342959344387\n",
      "[E: 21] loss: 0.027060557156801224, avg_loss: 0.027060557156801224\n",
      "[E: 22] loss: 0.009987139143049717, avg_loss: 0.009987139143049717\n",
      "[E: 23] loss: 0.001762162079103291, avg_loss: 0.001762162079103291\n",
      "[E: 25] loss: 0.00029952265322208405, avg_loss: 0.00029952265322208405\n",
      "[E: 26] loss: 0.00011028793232981116, avg_loss: 0.00011028793232981116\n",
      "[E: 27] loss: 0.001849242951720953, avg_loss: 0.001849242951720953\n",
      "[E: 28] loss: 0.0031012941617518663, avg_loss: 0.0031012941617518663\n",
      "[E: 29] loss: 0.0007785070338286459, avg_loss: 0.0007785070338286459\n",
      "Finished model training!\n",
      "Trainig duration: 0:25:28.360772\n",
      "Finished model vgg16_gan_augmented_sharp_blur_2000_old_gan_s_42 evaluation!\n",
      "Test acc: 0.8943452380952381\n",
      "Saved testing logs.\n",
      "3000 GAN images:\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 3000}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.7471519112586975, avg_loss: 0.7471519112586975\n",
      "[E: 1] loss: 0.8696911931037903, avg_loss: 0.8696911931037903\n",
      "[E: 2] loss: 0.557152271270752, avg_loss: 0.557152271270752\n",
      "[E: 3] loss: 0.4494953751564026, avg_loss: 0.4494953751564026\n",
      "[E: 4] loss: 0.18240197002887726, avg_loss: 0.18240197002887726\n",
      "[E: 5] loss: 0.2670370638370514, avg_loss: 0.2670370638370514\n",
      "[E: 6] loss: 0.1652597188949585, avg_loss: 0.1652597188949585\n",
      "[E: 7] loss: 0.16207419335842133, avg_loss: 0.16207419335842133\n",
      "[E: 8] loss: 0.055249739438295364, avg_loss: 0.055249739438295364\n",
      "[E: 9] loss: 0.1523856818675995, avg_loss: 0.1523856818675995\n",
      "[E: 10] loss: 0.03372713923454285, avg_loss: 0.03372713923454285\n",
      "[E: 11] loss: 0.0440959632396698, avg_loss: 0.0440959632396698\n",
      "[E: 12] loss: 0.01302214153110981, avg_loss: 0.01302214153110981\n",
      "[E: 13] loss: 0.06682781130075455, avg_loss: 0.06682781130075455\n",
      "[E: 14] loss: 0.05437258258461952, avg_loss: 0.05437258258461952\n",
      "[E: 15] loss: 0.018603825941681862, avg_loss: 0.018603825941681862\n",
      "[E: 16] loss: 0.00581848481670022, avg_loss: 0.00581848481670022\n",
      "[E: 17] loss: 0.024995267391204834, avg_loss: 0.024995267391204834\n",
      "[E: 18] loss: 0.0009399487171322107, avg_loss: 0.0009399487171322107\n",
      "[E: 19] loss: 0.002150206593796611, avg_loss: 0.002150206593796611\n",
      "[E: 20] loss: 0.000756270659621805, avg_loss: 0.000756270659621805\n",
      "[E: 21] loss: 0.04296990856528282, avg_loss: 0.04296990856528282\n",
      "[E: 22] loss: 0.0017176808323711157, avg_loss: 0.0017176808323711157\n",
      "[E: 23] loss: 0.003288921434432268, avg_loss: 0.003288921434432268\n",
      "[E: 24] loss: 0.00016157832578755915, avg_loss: 0.00016157832578755915\n",
      "[E: 25] loss: 0.00672004371881485, avg_loss: 0.00672004371881485\n",
      "[E: 26] loss: 0.004276010673493147, avg_loss: 0.004276010673493147\n",
      "[E: 27] loss: 0.006427537649869919, avg_loss: 0.006427537649869919\n",
      "[E: 28] loss: 0.001468494301661849, avg_loss: 0.001468494301661849\n",
      "[E: 29] loss: 0.031034063547849655, avg_loss: 0.031034063547849655\n",
      "[E: 30] loss: 0.003176771104335785, avg_loss: 0.003176771104335785\n",
      "[E: 31] loss: 0.00044472533045336604, avg_loss: 0.00044472533045336604\n",
      "[E: 32] loss: 0.06916932016611099, avg_loss: 0.06916932016611099\n",
      "[E: 33] loss: 0.006755041424185038, avg_loss: 0.006755041424185038\n",
      "Finished model training!\n",
      "Trainig duration: 0:32:53.672369\n",
      "Finished model vgg16_gan_augmented_sharp_blur_3000_old_gan_s_42 evaluation!\n",
      "Test acc: 0.9077380952380952\n",
      "Saved testing logs.\n",
      "4000 GAN images:\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 4000}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.7389020919799805, avg_loss: 0.7389020919799805\n",
      "[E: 1] loss: 0.7772181034088135, avg_loss: 0.7772181034088135\n",
      "[E: 2] loss: 0.5280346274375916, avg_loss: 0.5280346274375916\n",
      "[E: 3] loss: 0.41102057695388794, avg_loss: 0.41102057695388794\n",
      "[E: 4] loss: 0.4819137156009674, avg_loss: 0.4819137156009674\n",
      "[E: 5] loss: 0.2173316776752472, avg_loss: 0.2173316776752472\n",
      "[E: 6] loss: 0.2927477955818176, avg_loss: 0.2927477955818176\n",
      "[E: 7] loss: 0.2132616639137268, avg_loss: 0.2132616639137268\n",
      "[E: 8] loss: 0.07654908299446106, avg_loss: 0.07654908299446106\n",
      "[E: 9] loss: 0.1325339525938034, avg_loss: 0.1325339525938034\n",
      "[E: 10] loss: 0.2825682461261749, avg_loss: 0.2825682461261749\n",
      "[E: 11] loss: 0.025852516293525696, avg_loss: 0.025852516293525696\n",
      "[E: 12] loss: 0.0036680535413324833, avg_loss: 0.0036680535413324833\n",
      "[E: 13] loss: 0.15043610334396362, avg_loss: 0.15043610334396362\n",
      "[E: 14] loss: 0.03247023746371269, avg_loss: 0.03247023746371269\n",
      "[E: 15] loss: 0.039332181215286255, avg_loss: 0.039332181215286255\n",
      "[E: 16] loss: 0.02489238604903221, avg_loss: 0.02489238604903221\n",
      "[E: 17] loss: 0.029359888285398483, avg_loss: 0.029359888285398483\n",
      "[E: 18] loss: 0.06937462836503983, avg_loss: 0.06937462836503983\n",
      "[E: 19] loss: 0.0013175415806472301, avg_loss: 0.0013175415806472301\n",
      "[E: 20] loss: 0.07054528594017029, avg_loss: 0.07054528594017029\n",
      "[E: 21] loss: 0.025872744619846344, avg_loss: 0.025872744619846344\n",
      "[E: 22] loss: 0.00031693288474343717, avg_loss: 0.00031693288474343717\n",
      "[E: 23] loss: 0.03651004657149315, avg_loss: 0.03651004657149315\n",
      "[E: 24] loss: 0.09261515736579895, avg_loss: 0.09261515736579895\n",
      "[E: 25] loss: 0.0008839553338475525, avg_loss: 0.0008839553338475525\n",
      "[E: 26] loss: 0.0023558533284813166, avg_loss: 0.0023558533284813166\n",
      "[E: 27] loss: 0.003941091243177652, avg_loss: 0.003941091243177652\n",
      "[E: 28] loss: 0.003554773284122348, avg_loss: 0.003554773284122348\n",
      "[E: 29] loss: 0.003865935141220689, avg_loss: 0.003865935141220689\n",
      "[E: 30] loss: 0.02169845998287201, avg_loss: 0.02169845998287201\n",
      "[E: 31] loss: 0.17019042372703552, avg_loss: 0.17019042372703552\n",
      "[E: 32] loss: 0.00047540321247652173, avg_loss: 0.00047540321247652173\n",
      "[E: 33] loss: 0.15335553884506226, avg_loss: 0.15335553884506226\n",
      "[E: 34] loss: 0.00039968249620869756, avg_loss: 0.00039968249620869756\n",
      "[E: 35] loss: 0.0011498124804347754, avg_loss: 0.0011498124804347754\n",
      "[E: 36] loss: 0.005298141855746508, avg_loss: 0.005298141855746508\n",
      "[E: 37] loss: 0.0003824483137577772, avg_loss: 0.0003824483137577772\n",
      "[E: 38] loss: 0.002761209849268198, avg_loss: 0.002761209849268198\n",
      "[E: 39] loss: 0.008900081738829613, avg_loss: 0.008900081738829613\n",
      "[E: 40] loss: 0.00014315916632767767, avg_loss: 0.00014315916632767767\n",
      "[E: 41] loss: 0.0005153635866008699, avg_loss: 0.0005153635866008699\n",
      "[E: 42] loss: 0.004002048168331385, avg_loss: 0.004002048168331385\n",
      "[E: 43] loss: 0.0010059848427772522, avg_loss: 0.0010059848427772522\n",
      "Finished model training!\n",
      "Trainig duration: 0:48:29.115204\n",
      "Finished model vgg16_gan_augmented_sharp_blur_4000_old_gan_s_42 evaluation!\n",
      "Test acc: 0.9002976190476191\n",
      "Saved testing logs.\n",
      "5000 GAN images:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 5000}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.7514078617095947, avg_loss: 0.7514078617095947\n",
      "[E: 1] loss: 0.4970112442970276, avg_loss: 0.4970112442970276\n",
      "[E: 2] loss: 0.18590913712978363, avg_loss: 0.18590913712978363\n",
      "[E: 3] loss: 0.2997806966304779, avg_loss: 0.2997806966304779\n",
      "[E: 4] loss: 0.13439685106277466, avg_loss: 0.13439685106277466\n",
      "[E: 5] loss: 0.2912866473197937, avg_loss: 0.2912866473197937\n",
      "[E: 6] loss: 0.05592681095004082, avg_loss: 0.05592681095004082\n",
      "[E: 7] loss: 0.20297390222549438, avg_loss: 0.20297390222549438\n",
      "[E: 8] loss: 0.01377089787274599, avg_loss: 0.01377089787274599\n",
      "[E: 9] loss: 0.05768613889813423, avg_loss: 0.05768613889813423\n",
      "[E: 10] loss: 0.1087113469839096, avg_loss: 0.1087113469839096\n",
      "[E: 11] loss: 0.057024020701646805, avg_loss: 0.057024020701646805\n",
      "[E: 12] loss: 0.006295282859355211, avg_loss: 0.006295282859355211\n",
      "[E: 13] loss: 0.006484708748757839, avg_loss: 0.006484708748757839\n",
      "[E: 14] loss: 0.010212711058557034, avg_loss: 0.010212711058557034\n",
      "[E: 15] loss: 0.27694445848464966, avg_loss: 0.27694445848464966\n",
      "[E: 16] loss: 0.0038751934189349413, avg_loss: 0.0038751934189349413\n",
      "[E: 17] loss: 0.16452628374099731, avg_loss: 0.16452628374099731\n",
      "[E: 18] loss: 0.0033112738747149706, avg_loss: 0.0033112738747149706\n",
      "[E: 19] loss: 0.015018331818282604, avg_loss: 0.015018331818282604\n",
      "[E: 20] loss: 0.0009671344887465239, avg_loss: 0.0009671344887465239\n",
      "[E: 21] loss: 0.0032795879524201155, avg_loss: 0.0032795879524201155\n",
      "[E: 22] loss: 0.0008413430186919868, avg_loss: 0.0008413430186919868\n",
      "[E: 23] loss: 0.0003599253250285983, avg_loss: 0.0003599253250285983\n",
      "[E: 24] loss: 0.0002621606399770826, avg_loss: 0.0002621606399770826\n",
      "[E: 25] loss: 0.010703603737056255, avg_loss: 0.010703603737056255\n",
      "[E: 26] loss: 0.0007955572800710797, avg_loss: 0.0007955572800710797\n",
      "[E: 27] loss: 0.0002999714342877269, avg_loss: 0.0002999714342877269\n",
      "[E: 28] loss: 4.637429447029717e-05, avg_loss: 4.637429447029717e-05\n",
      "[E: 29] loss: 0.01339499931782484, avg_loss: 0.01339499931782484\n",
      "[E: 30] loss: 0.00029427968547679484, avg_loss: 0.00029427968547679484\n",
      "[E: 31] loss: 0.0001524737454019487, avg_loss: 0.0001524737454019487\n",
      "[E: 32] loss: 0.0003515424905344844, avg_loss: 0.0003515424905344844\n",
      "[E: 33] loss: 0.002556815044954419, avg_loss: 0.002556815044954419\n",
      "[E: 34] loss: 0.0009275074698962271, avg_loss: 0.0009275074698962271\n",
      "[E: 35] loss: 0.0006876986008137465, avg_loss: 0.0006876986008137465\n",
      "[E: 36] loss: 5.674742715200409e-05, avg_loss: 5.674742715200409e-05\n",
      "[E: 37] loss: 1.4699083294544835e-05, avg_loss: 1.4699083294544835e-05\n",
      "[E: 38] loss: 7.244206790346652e-05, avg_loss: 7.244206790346652e-05\n",
      "[E: 39] loss: 0.00011024659761460498, avg_loss: 0.00011024659761460498\n",
      "[E: 40] loss: 5.022893310524523e-05, avg_loss: 5.022893310524523e-05\n",
      "[E: 41] loss: 7.934622408356518e-05, avg_loss: 7.934622408356518e-05\n",
      "[E: 42] loss: 1.4292819287220482e-05, avg_loss: 1.4292819287220482e-05\n",
      "[E: 43] loss: 0.00010036135790869594, avg_loss: 0.00010036135790869594\n",
      "[E: 44] loss: 0.0006862010341137648, avg_loss: 0.0006862010341137648\n",
      "[E: 45] loss: 0.004851470235735178, avg_loss: 0.004851470235735178\n",
      "[E: 46] loss: 0.0012447232147678733, avg_loss: 0.0012447232147678733\n",
      "[E: 47] loss: 0.0001867476530605927, avg_loss: 0.0001867476530605927\n",
      "[E: 48] loss: 8.139013516483828e-05, avg_loss: 8.139013516483828e-05\n",
      "[E: 49] loss: 0.0019091624999418855, avg_loss: 0.0019091624999418855\n",
      "[E: 50] loss: 0.0002768321137409657, avg_loss: 0.0002768321137409657\n",
      "[E: 51] loss: 0.000306991656543687, avg_loss: 0.000306991656543687\n",
      "[E: 52] loss: 0.00040519502363167703, avg_loss: 0.00040519502363167703\n",
      "[E: 53] loss: 0.0010246823076158762, avg_loss: 0.0010246823076158762\n",
      "[E: 54] loss: 0.00026842698571272194, avg_loss: 0.00026842698571272194\n",
      "[E: 55] loss: 0.005266532767564058, avg_loss: 0.005266532767564058\n",
      "Finished model training!\n",
      "Trainig duration: 1:07:59.352639\n",
      "Finished model vgg16_gan_augmented_sharp_blur_5000_old_gan_s_42 evaluation!\n",
      "Test acc: 0.9181547619047619\n",
      "Saved testing logs.\n"
     ]
    }
   ],
   "source": [
    "aug_transform = transforms.Compose([\n",
    "    transforms.RandomApply([SharpenImage()], p=.2),\n",
    "    transforms.ToPILImage(),\n",
    "#     transforms.RandomHorizontalFlip(p=.2),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=3, sigma=(1,2))], p=.2),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "#     RandomRotationTransform(angles=[90,270, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.5],\n",
    "                         std  = [0.5]),\n",
    "])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.5],\n",
    "                         std  = [0.5]),\n",
    "    ])\n",
    "\n",
    "gen_adeno = \"generator_pggan_roi_adeno_all_data.pth.tar\"\n",
    "gen_squamous = \"generator_pggan_roi_squamous_all_data.pth.tar\"\n",
    "for SEED in [42]:\n",
    "    for no_gan_images in [0, 1000, 2000, 3000, 4000, 5000]:\n",
    "        seed_everything(SEED)\n",
    "        print(f\"{no_gan_images} GAN images:\")\n",
    "        delete_gan_images()\n",
    "        generate_images(\n",
    "            gen_squamous, no_gan_images // 2, 'LUSC', \"/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/train/images/\")\n",
    "        generate_images(\n",
    "            gen_adeno, no_gan_images // 2, 'LUAD', \"/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/train/images/\")\n",
    "        train_loader, val_loader, test_loader = get_loaders(\n",
    "            train_dir = TRAIN_DIR,\n",
    "            val_dir = VAL_DIR,\n",
    "            test_dir = TEST_DIR,\n",
    "            train_transform = aug_transform,\n",
    "            test_transform = transform,\n",
    "        )\n",
    "        gan_model = 'old_gan'\n",
    "        overwritten_model_name = f\"{TENSORBOARD_MODEL_NAME}_augmented_sharp_blur_{no_gan_images}_{gan_model}_s_{SEED}\"\n",
    "        model_name = train(train_loader, val_loader, overwritten_model_name=overwritten_model_name)\n",
    "        test(test_loader, model_name, gan_model=gan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af60bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_adeno = \"generator_pggan_roi_adeno_all_data.pth.tar\"\n",
    "gen_squamous = \"generator_pggan_roi_squamous_all_data.pth.tar\"\n",
    "for SEED in [42]:\n",
    "    for no_gan_images in [0, 1000, 2000, 3000, 4000, 5000]:\n",
    "        seed_everything(SEED)\n",
    "        print(f\"{no_gan_images} GAN images:\")\n",
    "        delete_gan_images()\n",
    "        generate_images(\n",
    "            gen_squamous, no_gan_images // 2, 'LUSC', \"/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/train/images/\")\n",
    "        generate_images(\n",
    "            gen_adeno, no_gan_images // 2, 'LUAD', \"/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/train/images/\")\n",
    "        train_loader, val_loader, test_loader = get_loaders(\n",
    "            train_dir = TRAIN_DIR,\n",
    "            val_dir = VAL_DIR,\n",
    "            test_dir = TEST_DIR,\n",
    "            transform = transform,\n",
    "        )\n",
    "        gan_model = 'old_gan'\n",
    "        model_name = train(train_loader, val_loader, gan=gan_model)\n",
    "        test(test_loader, model_name, gan_model=gan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "698f77a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 GAN images:\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 0}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.8512869477272034, avg_loss: 0.8512869477272034\n",
      "[E: 1] loss: 0.6348040103912354, avg_loss: 0.6348040103912354\n",
      "[E: 2] loss: 0.6898595094680786, avg_loss: 0.6898595094680786\n",
      "[E: 3] loss: 0.7726166844367981, avg_loss: 0.7726166844367981\n",
      "[E: 4] loss: 1.0005995035171509, avg_loss: 1.0005995035171509\n",
      "[E: 5] loss: 0.7265245318412781, avg_loss: 0.7265245318412781\n",
      "[E: 6] loss: 0.6235077977180481, avg_loss: 0.6235077977180481\n",
      "[E: 7] loss: 0.2916323244571686, avg_loss: 0.2916323244571686\n",
      "[E: 8] loss: 0.47286587953567505, avg_loss: 0.47286587953567505\n",
      "[E: 9] loss: 0.07735337316989899, avg_loss: 0.07735337316989899\n",
      "[E: 10] loss: 0.01513221301138401, avg_loss: 0.01513221301138401\n",
      "[E: 11] loss: 0.029895029962062836, avg_loss: 0.029895029962062836\n",
      "[E: 12] loss: 0.03139519691467285, avg_loss: 0.03139519691467285\n",
      "[E: 13] loss: 0.04485579580068588, avg_loss: 0.04485579580068588\n",
      "[E: 14] loss: 0.08497236669063568, avg_loss: 0.08497236669063568\n",
      "[E: 15] loss: 0.023942215368151665, avg_loss: 0.023942215368151665\n",
      "[E: 16] loss: 0.013166953809559345, avg_loss: 0.013166953809559345\n",
      "[E: 17] loss: 0.13734635710716248, avg_loss: 0.13734635710716248\n",
      "[E: 18] loss: 0.02186449244618416, avg_loss: 0.02186449244618416\n",
      "[E: 19] loss: 0.007703240495175123, avg_loss: 0.007703240495175123\n",
      "[E: 20] loss: 0.001369005418382585, avg_loss: 0.001369005418382585\n",
      "[E: 21] loss: 0.03513123095035553, avg_loss: 0.03513123095035553\n",
      "[E: 22] loss: 0.01492737140506506, avg_loss: 0.01492737140506506\n",
      "[E: 23] loss: 0.013673152774572372, avg_loss: 0.013673152774572372\n",
      "[E: 24] loss: 0.0013042129576206207, avg_loss: 0.0013042129576206207\n",
      "[E: 25] loss: 0.003766273846849799, avg_loss: 0.003766273846849799\n",
      "[E: 26] loss: 0.0031380741856992245, avg_loss: 0.0031380741856992245\n",
      "[E: 27] loss: 0.007296438328921795, avg_loss: 0.007296438328921795\n",
      "[E: 28] loss: 9.332589252153412e-05, avg_loss: 9.332589252153412e-05\n",
      "[E: 29] loss: 0.0020694383420050144, avg_loss: 0.0020694383420050144\n",
      "[E: 30] loss: 0.00018287116836290807, avg_loss: 0.00018287116836290807\n",
      "[E: 31] loss: 0.04792771488428116, avg_loss: 0.04792771488428116\n",
      "[E: 32] loss: 0.005551477894186974, avg_loss: 0.005551477894186974\n",
      "[E: 33] loss: 0.005613714922219515, avg_loss: 0.005613714922219515\n",
      "[E: 34] loss: 0.00037524328217841685, avg_loss: 0.00037524328217841685\n",
      "[E: 35] loss: 0.0007712264196015894, avg_loss: 0.0007712264196015894\n",
      "[E: 36] loss: 0.00028963692602701485, avg_loss: 0.00028963692602701485\n",
      "[E: 37] loss: 0.001820640405640006, avg_loss: 0.001820640405640006\n",
      "[E: 38] loss: 0.0011077749077230692, avg_loss: 0.0011077749077230692\n",
      "[E: 39] loss: 0.0037925359793007374, avg_loss: 0.0037925359793007374\n",
      "[E: 40] loss: 0.0010513464221730828, avg_loss: 0.0010513464221730828\n",
      "[E: 41] loss: 0.00019388175860513002, avg_loss: 0.00019388175860513002\n",
      "[E: 42] loss: 0.0012644761009141803, avg_loss: 0.0012644761009141803\n",
      "[E: 43] loss: 0.0011062382254749537, avg_loss: 0.0011062382254749537\n",
      "[E: 44] loss: 0.00045561057049781084, avg_loss: 0.00045561057049781084\n",
      "[E: 45] loss: 0.0002541140129324049, avg_loss: 0.0002541140129324049\n",
      "[E: 46] loss: 8.716160664334893e-05, avg_loss: 8.716160664334893e-05\n",
      "[E: 47] loss: 0.0002472208288963884, avg_loss: 0.0002472208288963884\n",
      "[E: 48] loss: 0.0001078493005479686, avg_loss: 0.0001078493005479686\n",
      "[E: 49] loss: 0.01627350226044655, avg_loss: 0.01627350226044655\n",
      "Finished model vgg16_gan_0_gan_augmented_rot_blur_sharp_s_42 evaluation!\n",
      "Test acc: 0.90625\n",
      "Saved testing logs.\n",
      "1000 GAN images:\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 1000}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.8175809383392334, avg_loss: 0.8175809383392334\n",
      "[E: 1] loss: 1.0891114473342896, avg_loss: 1.0891114473342896\n",
      "[E: 2] loss: 0.650854229927063, avg_loss: 0.650854229927063\n",
      "[E: 3] loss: 1.8939019441604614, avg_loss: 1.8939019441604614\n",
      "[E: 4] loss: 0.8568907976150513, avg_loss: 0.8568907976150513\n",
      "[E: 5] loss: 0.37738561630249023, avg_loss: 0.37738561630249023\n",
      "[E: 6] loss: 0.48902925848960876, avg_loss: 0.48902925848960876\n",
      "[E: 7] loss: 0.30897876620292664, avg_loss: 0.30897876620292664\n",
      "[E: 8] loss: 0.1031358391046524, avg_loss: 0.1031358391046524\n",
      "[E: 9] loss: 0.08492977917194366, avg_loss: 0.08492977917194366\n",
      "[E: 10] loss: 0.07345455884933472, avg_loss: 0.07345455884933472\n",
      "[E: 11] loss: 0.12550608813762665, avg_loss: 0.12550608813762665\n",
      "[E: 12] loss: 0.015504322946071625, avg_loss: 0.015504322946071625\n",
      "[E: 13] loss: 0.10399354249238968, avg_loss: 0.10399354249238968\n",
      "[E: 14] loss: 0.006956618744879961, avg_loss: 0.006956618744879961\n",
      "[E: 15] loss: 0.005282273981720209, avg_loss: 0.005282273981720209\n",
      "[E: 16] loss: 0.16770479083061218, avg_loss: 0.16770479083061218\n",
      "[E: 17] loss: 0.03416143357753754, avg_loss: 0.03416143357753754\n",
      "[E: 18] loss: 0.027452899143099785, avg_loss: 0.027452899143099785\n",
      "[E: 19] loss: 0.14227791130542755, avg_loss: 0.14227791130542755\n",
      "[E: 20] loss: 0.013622164726257324, avg_loss: 0.013622164726257324\n",
      "[E: 21] loss: 0.03734790161252022, avg_loss: 0.03734790161252022\n",
      "[E: 22] loss: 0.03879361227154732, avg_loss: 0.03879361227154732\n",
      "[E: 23] loss: 0.13641425967216492, avg_loss: 0.13641425967216492\n",
      "[E: 24] loss: 0.051498863846063614, avg_loss: 0.051498863846063614\n",
      "[E: 25] loss: 0.000423995777964592, avg_loss: 0.000423995777964592\n",
      "[E: 26] loss: 0.000556622922886163, avg_loss: 0.000556622922886163\n",
      "[E: 27] loss: 0.0009173558792099357, avg_loss: 0.0009173558792099357\n",
      "[E: 28] loss: 0.00018602420459501445, avg_loss: 0.00018602420459501445\n",
      "[E: 29] loss: 0.0005007475847378373, avg_loss: 0.0005007475847378373\n",
      "[E: 30] loss: 0.021960100159049034, avg_loss: 0.021960100159049034\n",
      "[E: 31] loss: 0.0006290979217737913, avg_loss: 0.0006290979217737913\n",
      "[E: 32] loss: 0.007083750795572996, avg_loss: 0.007083750795572996\n",
      "[E: 33] loss: 0.0031753694638609886, avg_loss: 0.0031753694638609886\n",
      "[E: 34] loss: 0.000544932612683624, avg_loss: 0.000544932612683624\n",
      "[E: 35] loss: 0.017614947631955147, avg_loss: 0.017614947631955147\n",
      "[E: 36] loss: 0.0018235238967463374, avg_loss: 0.0018235238967463374\n",
      "[E: 37] loss: 0.00024434810620732605, avg_loss: 0.00024434810620732605\n",
      "[E: 38] loss: 0.0002195114502683282, avg_loss: 0.0002195114502683282\n",
      "[E: 39] loss: 0.009092314168810844, avg_loss: 0.009092314168810844\n",
      "[E: 40] loss: 0.046013981103897095, avg_loss: 0.046013981103897095\n",
      "[E: 41] loss: 0.013124315068125725, avg_loss: 0.013124315068125725\n",
      "[E: 42] loss: 0.0006009891512803733, avg_loss: 0.0006009891512803733\n",
      "[E: 43] loss: 8.213979162974283e-05, avg_loss: 8.213979162974283e-05\n",
      "[E: 44] loss: 0.00042935999226756394, avg_loss: 0.00042935999226756394\n",
      "[E: 45] loss: 0.0015771370381116867, avg_loss: 0.0015771370381116867\n",
      "[E: 46] loss: 0.0007418903987854719, avg_loss: 0.0007418903987854719\n",
      "[E: 47] loss: 0.00015117810107767582, avg_loss: 0.00015117810107767582\n",
      "[E: 48] loss: 0.0005584466853179038, avg_loss: 0.0005584466853179038\n",
      "[E: 49] loss: 0.00016869185492396355, avg_loss: 0.00016869185492396355\n",
      "[E: 50] loss: 0.0006389131885953248, avg_loss: 0.0006389131885953248\n",
      "[E: 51] loss: 0.0032258499413728714, avg_loss: 0.0032258499413728714\n",
      "[E: 52] loss: 0.0002626958303153515, avg_loss: 0.0002626958303153515\n",
      "[E: 53] loss: 2.7370704628992826e-05, avg_loss: 2.7370704628992826e-05\n",
      "[E: 54] loss: 0.0001460829662391916, avg_loss: 0.0001460829662391916\n",
      "[E: 55] loss: 1.8135344362235628e-05, avg_loss: 1.8135344362235628e-05\n",
      "[E: 56] loss: 3.538574674166739e-05, avg_loss: 3.538574674166739e-05\n",
      "[E: 57] loss: 1.7864585970528424e-05, avg_loss: 1.7864585970528424e-05\n",
      "[E: 58] loss: 2.5871433535940014e-05, avg_loss: 2.5871433535940014e-05\n",
      "[E: 59] loss: 0.0012085824273526669, avg_loss: 0.0012085824273526669\n",
      "[E: 60] loss: 4.660287231672555e-06, avg_loss: 4.660287231672555e-06\n",
      "[E: 61] loss: 0.06842152774333954, avg_loss: 0.06842152774333954\n",
      "[E: 62] loss: 3.873601235682145e-05, avg_loss: 3.873601235682145e-05\n",
      "Finished model vgg16_gan_1000_gan_augmented_rot_blur_sharp_s_42 evaluation!\n",
      "Test acc: 0.9181547619047619\n",
      "Saved testing logs.\n",
      "2000 GAN images:\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 2000}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.7963451743125916, avg_loss: 0.7963451743125916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E: 1] loss: 0.8088873624801636, avg_loss: 0.8088873624801636\n",
      "[E: 2] loss: 0.5457770824432373, avg_loss: 0.5457770824432373\n",
      "[E: 3] loss: 0.8673291206359863, avg_loss: 0.8673291206359863\n",
      "[E: 4] loss: 0.4374731779098511, avg_loss: 0.4374731779098511\n",
      "[E: 5] loss: 0.2874881327152252, avg_loss: 0.2874881327152252\n",
      "[E: 6] loss: 0.15612030029296875, avg_loss: 0.15612030029296875\n",
      "[E: 7] loss: 0.26222261786460876, avg_loss: 0.26222261786460876\n",
      "[E: 8] loss: 0.09325763583183289, avg_loss: 0.09325763583183289\n",
      "[E: 9] loss: 0.09389194846153259, avg_loss: 0.09389194846153259\n",
      "[E: 10] loss: 0.02456684783101082, avg_loss: 0.02456684783101082\n",
      "[E: 11] loss: 0.09063897281885147, avg_loss: 0.09063897281885147\n",
      "[E: 12] loss: 0.0299706868827343, avg_loss: 0.0299706868827343\n",
      "[E: 13] loss: 0.028576567769050598, avg_loss: 0.028576567769050598\n",
      "[E: 14] loss: 0.2878071665763855, avg_loss: 0.2878071665763855\n",
      "[E: 15] loss: 0.04011151194572449, avg_loss: 0.04011151194572449\n",
      "[E: 16] loss: 0.003602058393880725, avg_loss: 0.003602058393880725\n",
      "[E: 17] loss: 0.05611163750290871, avg_loss: 0.05611163750290871\n",
      "[E: 18] loss: 0.0018827744061127305, avg_loss: 0.0018827744061127305\n",
      "[E: 19] loss: 0.006289589684456587, avg_loss: 0.006289589684456587\n",
      "[E: 20] loss: 0.0047250124625861645, avg_loss: 0.0047250124625861645\n",
      "[E: 21] loss: 0.0010700031416490674, avg_loss: 0.0010700031416490674\n",
      "[E: 22] loss: 0.0065379696898162365, avg_loss: 0.0065379696898162365\n",
      "[E: 23] loss: 0.17071649432182312, avg_loss: 0.17071649432182312\n",
      "[E: 24] loss: 0.013438038527965546, avg_loss: 0.013438038527965546\n",
      "[E: 25] loss: 0.0010831382824108005, avg_loss: 0.0010831382824108005\n",
      "[E: 26] loss: 0.002365595893934369, avg_loss: 0.002365595893934369\n",
      "[E: 27] loss: 0.0042479136027395725, avg_loss: 0.0042479136027395725\n",
      "[E: 28] loss: 0.0009413286461494863, avg_loss: 0.0009413286461494863\n",
      "[E: 29] loss: 0.015113480389118195, avg_loss: 0.015113480389118195\n",
      "[E: 30] loss: 0.00038286816561594605, avg_loss: 0.00038286816561594605\n",
      "[E: 31] loss: 0.19388581812381744, avg_loss: 0.19388581812381744\n",
      "[E: 32] loss: 0.00016727892216295004, avg_loss: 0.00016727892216295004\n",
      "[E: 33] loss: 0.0013367199571803212, avg_loss: 0.0013367199571803212\n",
      "[E: 34] loss: 0.00030934339156374335, avg_loss: 0.00030934339156374335\n",
      "[E: 35] loss: 0.00023003490059636533, avg_loss: 0.00023003490059636533\n",
      "[E: 36] loss: 0.0009321144316345453, avg_loss: 0.0009321144316345453\n",
      "[E: 37] loss: 0.0010894634760916233, avg_loss: 0.0010894634760916233\n",
      "[E: 38] loss: 0.0007685513701289892, avg_loss: 0.0007685513701289892\n",
      "[E: 39] loss: 0.000489372992888093, avg_loss: 0.000489372992888093\n",
      "[E: 40] loss: 0.018963368609547615, avg_loss: 0.018963368609547615\n",
      "[E: 41] loss: 0.00042194456909783185, avg_loss: 0.00042194456909783185\n",
      "[E: 42] loss: 0.03897574916481972, avg_loss: 0.03897574916481972\n",
      "[E: 43] loss: 0.0020858589559793472, avg_loss: 0.0020858589559793472\n",
      "[E: 44] loss: 0.00046096666483208537, avg_loss: 0.00046096666483208537\n",
      "[E: 45] loss: 0.001954970881342888, avg_loss: 0.001954970881342888\n",
      "[E: 46] loss: 7.606399594806135e-05, avg_loss: 7.606399594806135e-05\n",
      "[E: 47] loss: 0.00011989503400400281, avg_loss: 0.00011989503400400281\n",
      "[E: 48] loss: 0.001606303034350276, avg_loss: 0.001606303034350276\n",
      "[E: 49] loss: 0.004862481728196144, avg_loss: 0.004862481728196144\n",
      "[E: 50] loss: 0.00011891625035787001, avg_loss: 0.00011891625035787001\n",
      "[E: 51] loss: 0.0003755961952265352, avg_loss: 0.0003755961952265352\n",
      "[E: 52] loss: 0.0004832132544834167, avg_loss: 0.0004832132544834167\n",
      "[E: 53] loss: 0.009279545396566391, avg_loss: 0.009279545396566391\n",
      "[E: 54] loss: 0.00020858504285570234, avg_loss: 0.00020858504285570234\n",
      "[E: 55] loss: 0.0001240789279108867, avg_loss: 0.0001240789279108867\n",
      "[E: 56] loss: 0.000320560357067734, avg_loss: 0.000320560357067734\n",
      "[E: 57] loss: 0.00034042360493913293, avg_loss: 0.00034042360493913293\n",
      "[E: 58] loss: 0.0005460848333314061, avg_loss: 0.0005460848333314061\n",
      "[E: 59] loss: 0.00016036401211749762, avg_loss: 0.00016036401211749762\n",
      "[E: 60] loss: 0.00019380995945539325, avg_loss: 0.00019380995945539325\n",
      "[E: 61] loss: 0.022481605410575867, avg_loss: 0.022481605410575867\n",
      "[E: 62] loss: 0.0001527777931187302, avg_loss: 0.0001527777931187302\n",
      "[E: 63] loss: 1.2408394468366168e-05, avg_loss: 1.2408394468366168e-05\n",
      "[E: 64] loss: 4.9887923523783684e-05, avg_loss: 4.9887923523783684e-05\n",
      "[E: 65] loss: 0.03200725466012955, avg_loss: 0.03200725466012955\n",
      "[E: 66] loss: 0.0008723768405616283, avg_loss: 0.0008723768405616283\n",
      "[E: 67] loss: 0.00048690635594539344, avg_loss: 0.00048690635594539344\n",
      "[E: 68] loss: 0.001538009848445654, avg_loss: 0.001538009848445654\n",
      "[E: 69] loss: 5.416604835772887e-05, avg_loss: 5.416604835772887e-05\n",
      "[E: 70] loss: 0.00020301468612160534, avg_loss: 0.00020301468612160534\n",
      "[E: 71] loss: 0.001230940455570817, avg_loss: 0.001230940455570817\n",
      "[E: 72] loss: 3.493532130960375e-05, avg_loss: 3.493532130960375e-05\n",
      "[E: 73] loss: 0.0011477019870653749, avg_loss: 0.0011477019870653749\n",
      "Finished model vgg16_gan_2000_gan_augmented_rot_blur_sharp_s_42 evaluation!\n",
      "Test acc: 0.9136904761904762\n",
      "Saved testing logs.\n",
      "3000 GAN images:\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 3000}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.7519556283950806, avg_loss: 0.7519556283950806\n",
      "[E: 1] loss: 0.6392867565155029, avg_loss: 0.6392867565155029\n",
      "[E: 2] loss: 0.67881840467453, avg_loss: 0.67881840467453\n",
      "[E: 3] loss: 0.4592452645301819, avg_loss: 0.4592452645301819\n",
      "[E: 4] loss: 0.19303789734840393, avg_loss: 0.19303789734840393\n",
      "[E: 5] loss: 0.27588582038879395, avg_loss: 0.27588582038879395\n",
      "[E: 6] loss: 0.2640692889690399, avg_loss: 0.2640692889690399\n",
      "[E: 7] loss: 0.2040456086397171, avg_loss: 0.2040456086397171\n",
      "[E: 8] loss: 0.08121875673532486, avg_loss: 0.08121875673532486\n",
      "[E: 9] loss: 0.06184084340929985, avg_loss: 0.06184084340929985\n",
      "[E: 10] loss: 0.004494321532547474, avg_loss: 0.004494321532547474\n",
      "[E: 11] loss: 0.04832182824611664, avg_loss: 0.04832182824611664\n",
      "[E: 12] loss: 0.002897684695199132, avg_loss: 0.002897684695199132\n",
      "[E: 13] loss: 0.13547565042972565, avg_loss: 0.13547565042972565\n",
      "[E: 14] loss: 0.002401909092441201, avg_loss: 0.002401909092441201\n",
      "[E: 15] loss: 0.016086317598819733, avg_loss: 0.016086317598819733\n",
      "[E: 16] loss: 0.2580093443393707, avg_loss: 0.2580093443393707\n",
      "[E: 17] loss: 0.04295748844742775, avg_loss: 0.04295748844742775\n",
      "[E: 18] loss: 0.005571394227445126, avg_loss: 0.005571394227445126\n",
      "[E: 19] loss: 0.10324595123529434, avg_loss: 0.10324595123529434\n",
      "[E: 20] loss: 0.026161115616559982, avg_loss: 0.026161115616559982\n",
      "[E: 21] loss: 0.0387997142970562, avg_loss: 0.0387997142970562\n",
      "[E: 22] loss: 0.00025639228988438845, avg_loss: 0.00025639228988438845\n",
      "[E: 23] loss: 0.09413120895624161, avg_loss: 0.09413120895624161\n",
      "[E: 24] loss: 0.01400744542479515, avg_loss: 0.01400744542479515\n",
      "[E: 25] loss: 0.0021293959580361843, avg_loss: 0.0021293959580361843\n",
      "[E: 26] loss: 0.059400442987680435, avg_loss: 0.059400442987680435\n",
      "[E: 27] loss: 0.09214665740728378, avg_loss: 0.09214665740728378\n",
      "[E: 28] loss: 0.009775363840162754, avg_loss: 0.009775363840162754\n",
      "[E: 29] loss: 0.0016528067644685507, avg_loss: 0.0016528067644685507\n",
      "[E: 30] loss: 0.00029366507078520954, avg_loss: 0.00029366507078520954\n",
      "[E: 31] loss: 0.018352946266531944, avg_loss: 0.018352946266531944\n",
      "Finished model vgg16_gan_3000_gan_augmented_rot_blur_sharp_s_42 evaluation!\n",
      "Test acc: 0.9107142857142857\n",
      "Saved testing logs.\n",
      "4000 GAN images:\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 4000}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.7659185528755188, avg_loss: 0.7659185528755188\n",
      "[E: 1] loss: 0.5136343836784363, avg_loss: 0.5136343836784363\n",
      "[E: 2] loss: 0.716928243637085, avg_loss: 0.716928243637085\n",
      "[E: 3] loss: 0.7740374803543091, avg_loss: 0.7740374803543091\n",
      "[E: 4] loss: 0.2890619933605194, avg_loss: 0.2890619933605194\n",
      "[E: 5] loss: 0.23022696375846863, avg_loss: 0.23022696375846863\n",
      "[E: 6] loss: 0.23191829025745392, avg_loss: 0.23191829025745392\n",
      "[E: 7] loss: 0.13848184049129486, avg_loss: 0.13848184049129486\n",
      "[E: 8] loss: 0.07678361237049103, avg_loss: 0.07678361237049103\n",
      "[E: 9] loss: 0.16735178232192993, avg_loss: 0.16735178232192993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E: 10] loss: 0.004341069143265486, avg_loss: 0.004341069143265486\n",
      "[E: 11] loss: 0.029069649055600166, avg_loss: 0.029069649055600166\n",
      "[E: 12] loss: 0.01683320850133896, avg_loss: 0.01683320850133896\n",
      "[E: 13] loss: 0.008926003240048885, avg_loss: 0.008926003240048885\n",
      "[E: 14] loss: 0.010788977146148682, avg_loss: 0.010788977146148682\n",
      "[E: 15] loss: 0.02988056093454361, avg_loss: 0.02988056093454361\n",
      "[E: 16] loss: 0.0050187138840556145, avg_loss: 0.0050187138840556145\n",
      "[E: 17] loss: 0.1706395000219345, avg_loss: 0.1706395000219345\n",
      "[E: 18] loss: 0.004850083962082863, avg_loss: 0.004850083962082863\n",
      "[E: 19] loss: 0.01684359833598137, avg_loss: 0.01684359833598137\n",
      "[E: 20] loss: 0.02656053565442562, avg_loss: 0.02656053565442562\n",
      "[E: 21] loss: 0.0008452652837149799, avg_loss: 0.0008452652837149799\n",
      "[E: 22] loss: 0.01608157716691494, avg_loss: 0.01608157716691494\n",
      "[E: 23] loss: 0.0016689600888639688, avg_loss: 0.0016689600888639688\n",
      "[E: 24] loss: 0.001165078254416585, avg_loss: 0.001165078254416585\n",
      "[E: 25] loss: 0.00032074711634777486, avg_loss: 0.00032074711634777486\n",
      "[E: 26] loss: 0.002195738721638918, avg_loss: 0.002195738721638918\n",
      "[E: 27] loss: 0.00029333593556657434, avg_loss: 0.00029333593556657434\n",
      "[E: 28] loss: 0.0034469659440219402, avg_loss: 0.0034469659440219402\n",
      "[E: 29] loss: 0.03806707635521889, avg_loss: 0.03806707635521889\n",
      "[E: 30] loss: 0.0013337555574253201, avg_loss: 0.0013337555574253201\n",
      "[E: 31] loss: 6.292062607826665e-05, avg_loss: 6.292062607826665e-05\n",
      "[E: 32] loss: 0.06951954215765, avg_loss: 0.06951954215765\n",
      "[E: 33] loss: 0.0002443160628899932, avg_loss: 0.0002443160628899932\n",
      "[E: 34] loss: 0.0004892978467978537, avg_loss: 0.0004892978467978537\n",
      "[E: 35] loss: 0.0004753467219416052, avg_loss: 0.0004753467219416052\n",
      "[E: 36] loss: 0.005810233764350414, avg_loss: 0.005810233764350414\n",
      "[E: 37] loss: 0.0004471479041967541, avg_loss: 0.0004471479041967541\n",
      "[E: 38] loss: 0.0019172042375430465, avg_loss: 0.0019172042375430465\n",
      "[E: 39] loss: 0.03979966789484024, avg_loss: 0.03979966789484024\n",
      "[E: 40] loss: 0.0005280476179905236, avg_loss: 0.0005280476179905236\n",
      "[E: 41] loss: 0.001286128768697381, avg_loss: 0.001286128768697381\n",
      "[E: 42] loss: 0.0007680742419324815, avg_loss: 0.0007680742419324815\n",
      "[E: 43] loss: 0.00026635773247107863, avg_loss: 0.00026635773247107863\n",
      "[E: 44] loss: 0.0004797356959898025, avg_loss: 0.0004797356959898025\n",
      "[E: 45] loss: 4.908592745778151e-05, avg_loss: 4.908592745778151e-05\n",
      "[E: 46] loss: 0.0011595962569117546, avg_loss: 0.0011595962569117546\n",
      "[E: 47] loss: 8.835815242491663e-05, avg_loss: 8.835815242491663e-05\n",
      "[E: 48] loss: 0.001314011518843472, avg_loss: 0.001314011518843472\n",
      "[E: 49] loss: 0.0006289728335104883, avg_loss: 0.0006289728335104883\n",
      "[E: 50] loss: 0.0029640451539307833, avg_loss: 0.0029640451539307833\n",
      "[E: 51] loss: 0.0014338071923702955, avg_loss: 0.0014338071923702955\n",
      "[E: 52] loss: 0.0012721254024654627, avg_loss: 0.0012721254024654627\n",
      "[E: 53] loss: 0.002416411880403757, avg_loss: 0.002416411880403757\n",
      "[E: 54] loss: 0.00010058281623059884, avg_loss: 0.00010058281623059884\n",
      "[E: 55] loss: 0.00011431329767219722, avg_loss: 0.00011431329767219722\n",
      "[E: 56] loss: 5.984044400975108e-05, avg_loss: 5.984044400975108e-05\n",
      "[E: 57] loss: 9.725476411404088e-05, avg_loss: 9.725476411404088e-05\n",
      "[E: 58] loss: 2.3492997570428997e-05, avg_loss: 2.3492997570428997e-05\n",
      "[E: 59] loss: 3.93037153116893e-05, avg_loss: 3.93037153116893e-05\n",
      "[E: 60] loss: 7.256777462316677e-05, avg_loss: 7.256777462316677e-05\n",
      "[E: 61] loss: 9.214629244524986e-05, avg_loss: 9.214629244524986e-05\n",
      "[E: 62] loss: 0.0003652065061032772, avg_loss: 0.0003652065061032772\n",
      "[E: 63] loss: 8.671251271152869e-05, avg_loss: 8.671251271152869e-05\n",
      "[E: 64] loss: 0.008909284137189388, avg_loss: 0.008909284137189388\n",
      "[E: 65] loss: 0.0007132799946703017, avg_loss: 0.0007132799946703017\n",
      "[E: 66] loss: 0.000332214985974133, avg_loss: 0.000332214985974133\n",
      "[E: 67] loss: 0.014714490622282028, avg_loss: 0.014714490622282028\n",
      "[E: 68] loss: 0.00029862503288313746, avg_loss: 0.00029862503288313746\n",
      "[E: 69] loss: 7.735288090771064e-05, avg_loss: 7.735288090771064e-05\n",
      "[E: 70] loss: 7.069543789839372e-05, avg_loss: 7.069543789839372e-05\n",
      "Finished model vgg16_gan_4000_gan_augmented_rot_blur_sharp_s_42 evaluation!\n",
      "Test acc: 0.9255952380952381\n",
      "Saved testing logs.\n",
      "5000 GAN images:\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 5000}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.6557629704475403, avg_loss: 0.6557629704475403\n",
      "[E: 1] loss: 1.0047203302383423, avg_loss: 1.0047203302383423\n",
      "[E: 2] loss: 0.4822765290737152, avg_loss: 0.4822765290737152\n",
      "[E: 3] loss: 0.42690709233283997, avg_loss: 0.42690709233283997\n",
      "[E: 4] loss: 0.3422239422798157, avg_loss: 0.3422239422798157\n",
      "[E: 5] loss: 0.15122520923614502, avg_loss: 0.15122520923614502\n",
      "[E: 6] loss: 0.15255016088485718, avg_loss: 0.15255016088485718\n",
      "[E: 7] loss: 0.1949852705001831, avg_loss: 0.1949852705001831\n",
      "[E: 8] loss: 0.2047213613986969, avg_loss: 0.2047213613986969\n",
      "[E: 9] loss: 0.024251122027635574, avg_loss: 0.024251122027635574\n",
      "[E: 10] loss: 0.14940838515758514, avg_loss: 0.14940838515758514\n",
      "[E: 11] loss: 0.011037163436412811, avg_loss: 0.011037163436412811\n",
      "[E: 12] loss: 0.012302350252866745, avg_loss: 0.012302350252866745\n",
      "[E: 13] loss: 0.0074342298321425915, avg_loss: 0.0074342298321425915\n",
      "[E: 14] loss: 0.004092484246939421, avg_loss: 0.004092484246939421\n",
      "[E: 15] loss: 0.13033539056777954, avg_loss: 0.13033539056777954\n",
      "[E: 16] loss: 0.006733552552759647, avg_loss: 0.006733552552759647\n",
      "[E: 17] loss: 0.0030332845635712147, avg_loss: 0.0030332845635712147\n",
      "[E: 18] loss: 0.01050278078764677, avg_loss: 0.01050278078764677\n",
      "[E: 19] loss: 0.02301885187625885, avg_loss: 0.02301885187625885\n",
      "[E: 20] loss: 0.0068900808691978455, avg_loss: 0.0068900808691978455\n",
      "[E: 21] loss: 0.00409097783267498, avg_loss: 0.00409097783267498\n",
      "[E: 22] loss: 0.02259736694395542, avg_loss: 0.02259736694395542\n",
      "[E: 23] loss: 0.00037102701026014984, avg_loss: 0.00037102701026014984\n",
      "[E: 24] loss: 0.12012787163257599, avg_loss: 0.12012787163257599\n",
      "[E: 25] loss: 0.0025384179316461086, avg_loss: 0.0025384179316461086\n",
      "[E: 26] loss: 0.0020339353941380978, avg_loss: 0.0020339353941380978\n",
      "[E: 27] loss: 0.0028886853251606226, avg_loss: 0.0028886853251606226\n",
      "[E: 28] loss: 0.00046875461703166366, avg_loss: 0.00046875461703166366\n",
      "[E: 29] loss: 0.003448044415563345, avg_loss: 0.003448044415563345\n",
      "[E: 30] loss: 0.003423711284995079, avg_loss: 0.003423711284995079\n",
      "[E: 31] loss: 0.00046691729221493006, avg_loss: 0.00046691729221493006\n",
      "[E: 32] loss: 0.03452162817120552, avg_loss: 0.03452162817120552\n",
      "[E: 33] loss: 0.00015163590433076024, avg_loss: 0.00015163590433076024\n",
      "[E: 34] loss: 6.230520375538617e-05, avg_loss: 6.230520375538617e-05\n",
      "[E: 35] loss: 0.00049595843302086, avg_loss: 0.00049595843302086\n",
      "[E: 36] loss: 0.009628954343497753, avg_loss: 0.009628954343497753\n",
      "[E: 37] loss: 0.0012936413986608386, avg_loss: 0.0012936413986608386\n",
      "[E: 38] loss: 0.00023975262593012303, avg_loss: 0.00023975262593012303\n",
      "[E: 39] loss: 9.431756916455925e-05, avg_loss: 9.431756916455925e-05\n",
      "[E: 40] loss: 0.00018314310000278056, avg_loss: 0.00018314310000278056\n",
      "[E: 41] loss: 7.517020276281983e-05, avg_loss: 7.517020276281983e-05\n",
      "[E: 42] loss: 0.00010550233128014952, avg_loss: 0.00010550233128014952\n",
      "[E: 43] loss: 0.000292435783194378, avg_loss: 0.000292435783194378\n",
      "[E: 44] loss: 0.001874576206319034, avg_loss: 0.001874576206319034\n",
      "[E: 45] loss: 0.00034301591222174466, avg_loss: 0.00034301591222174466\n",
      "[E: 46] loss: 0.004696004092693329, avg_loss: 0.004696004092693329\n",
      "[E: 47] loss: 9.630349086364731e-05, avg_loss: 9.630349086364731e-05\n",
      "[E: 48] loss: 0.00018032424850389361, avg_loss: 0.00018032424850389361\n",
      "[E: 49] loss: 0.00035887022386305034, avg_loss: 0.00035887022386305034\n",
      "[E: 50] loss: 3.679627479868941e-05, avg_loss: 3.679627479868941e-05\n",
      "[E: 51] loss: 0.00013694239896722138, avg_loss: 0.00013694239896722138\n",
      "[E: 52] loss: 0.00010949130228254944, avg_loss: 0.00010949130228254944\n",
      "Finished model vgg16_gan_5000_gan_augmented_rot_blur_sharp_s_42 evaluation!\n",
      "Test acc: 0.9047619047619048\n",
      "Saved testing logs.\n"
     ]
    }
   ],
   "source": [
    "gen_adeno = \"generator_pggan_roi_adeno_epochs_50_alpha_0.75_aug_rot_blur_sharp.pth.tar\"\n",
    "gen_squamous = \"generator_pggan_roi_squamous_epochs_50_alpha_0.75_aug_rot_blur_sharp.pth.tar\"\n",
    "for SEED in [42]:\n",
    "    for no_gan_images in [0, 1000, 2000, 3000, 4000, 5000]:\n",
    "        seed_everything(SEED)\n",
    "        print(f\"{no_gan_images} GAN images:\")\n",
    "        delete_gan_images()\n",
    "        generate_images(\n",
    "            gen_squamous, no_gan_images // 2, 'LUSC', \"/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/train/images/\")\n",
    "        generate_images(\n",
    "            gen_adeno, no_gan_images // 2, 'LUAD', \"/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/train/images/\")\n",
    "        train_loader, val_loader, test_loader = get_loaders(\n",
    "            train_dir = TRAIN_DIR,\n",
    "            val_dir = VAL_DIR,\n",
    "            test_dir = TEST_DIR,\n",
    "            transform = transform,\n",
    "        )\n",
    "        gan_model = 'gan_augmented_rot_blur_sharp'\n",
    "        model_name = train(train_loader, val_loader, gan=gan_model)\n",
    "        test(test_loader, model_name, gan_model=gan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d941211",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750 GAN images:\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 3750}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.7698305249214172, avg_loss: 0.7698305249214172\n",
      "[E: 1] loss: 0.6860306859016418, avg_loss: 0.6860306859016418\n",
      "[E: 2] loss: 0.48612695932388306, avg_loss: 0.48612695932388306\n",
      "[E: 3] loss: 0.24988311529159546, avg_loss: 0.24988311529159546\n",
      "[E: 4] loss: 0.32356539368629456, avg_loss: 0.32356539368629456\n",
      "[E: 5] loss: 0.07273389399051666, avg_loss: 0.07273389399051666\n",
      "[E: 6] loss: 0.10050757974386215, avg_loss: 0.10050757974386215\n",
      "[E: 7] loss: 0.024713989347219467, avg_loss: 0.024713989347219467\n",
      "[E: 8] loss: 0.04186415672302246, avg_loss: 0.04186415672302246\n",
      "[E: 9] loss: 0.20877602696418762, avg_loss: 0.20877602696418762\n",
      "[E: 10] loss: 0.012968921102583408, avg_loss: 0.012968921102583408\n",
      "[E: 11] loss: 0.04311098903417587, avg_loss: 0.04311098903417587\n",
      "[E: 12] loss: 0.04963165894150734, avg_loss: 0.04963165894150734\n",
      "[E: 13] loss: 0.038079872727394104, avg_loss: 0.038079872727394104\n",
      "[E: 14] loss: 0.0034311406780034304, avg_loss: 0.0034311406780034304\n",
      "[E: 15] loss: 0.01032907236367464, avg_loss: 0.01032907236367464\n",
      "[E: 16] loss: 0.04063374176621437, avg_loss: 0.04063374176621437\n",
      "[E: 17] loss: 0.0021195856388658285, avg_loss: 0.0021195856388658285\n",
      "[E: 18] loss: 0.0012734722113236785, avg_loss: 0.0012734722113236785\n",
      "[E: 19] loss: 0.0007441799389198422, avg_loss: 0.0007441799389198422\n",
      "[E: 20] loss: 0.004083849489688873, avg_loss: 0.004083849489688873\n",
      "[E: 21] loss: 0.0018152366392314434, avg_loss: 0.0018152366392314434\n",
      "[E: 22] loss: 0.003040286945179105, avg_loss: 0.003040286945179105\n",
      "[E: 23] loss: 0.00039688291144557297, avg_loss: 0.00039688291144557297\n",
      "[E: 24] loss: 0.009663227945566177, avg_loss: 0.009663227945566177\n",
      "[E: 25] loss: 0.00025650914176367223, avg_loss: 0.00025650914176367223\n",
      "[E: 26] loss: 0.007821107283234596, avg_loss: 0.007821107283234596\n",
      "[E: 27] loss: 0.0608508475124836, avg_loss: 0.0608508475124836\n",
      "[E: 28] loss: 0.022381173446774483, avg_loss: 0.022381173446774483\n",
      "[E: 29] loss: 0.004382704850286245, avg_loss: 0.004382704850286245\n",
      "[E: 30] loss: 0.00017681176541373134, avg_loss: 0.00017681176541373134\n",
      "[E: 31] loss: 0.07543183863162994, avg_loss: 0.07543183863162994\n",
      "[E: 32] loss: 0.007783245295286179, avg_loss: 0.007783245295286179\n",
      "[E: 34] loss: 0.00011347504187142476, avg_loss: 0.00011347504187142476\n",
      "[E: 35] loss: 0.005271752830594778, avg_loss: 0.005271752830594778\n",
      "[E: 36] loss: 0.0012853656662628055, avg_loss: 0.0012853656662628055\n",
      "[E: 37] loss: 0.0011135428212583065, avg_loss: 0.0011135428212583065\n",
      "[E: 38] loss: 0.0006232516607269645, avg_loss: 0.0006232516607269645\n",
      "[E: 39] loss: 0.0011637932620942593, avg_loss: 0.0011637932620942593\n",
      "[E: 40] loss: 0.0004127926949877292, avg_loss: 0.0004127926949877292\n",
      "[E: 41] loss: 0.0002356842451263219, avg_loss: 0.0002356842451263219\n",
      "[E: 42] loss: 0.004769188351929188, avg_loss: 0.004769188351929188\n",
      "[E: 43] loss: 0.003328619059175253, avg_loss: 0.003328619059175253\n",
      "[E: 44] loss: 0.0030916291289031506, avg_loss: 0.0030916291289031506\n",
      "[E: 45] loss: 9.467711788602173e-05, avg_loss: 9.467711788602173e-05\n",
      "[E: 46] loss: 0.0021158712916076183, avg_loss: 0.0021158712916076183\n",
      "[E: 47] loss: 0.00023889780277386308, avg_loss: 0.00023889780277386308\n",
      "[E: 48] loss: 0.1415615826845169, avg_loss: 0.1415615826845169\n",
      "[E: 49] loss: 0.0035730914678424597, avg_loss: 0.0035730914678424597\n",
      "[E: 50] loss: 0.0011732862330973148, avg_loss: 0.0011732862330973148\n",
      "[E: 51] loss: 0.00019152741879224777, avg_loss: 0.00019152741879224777\n",
      "[E: 52] loss: 0.0003106363001279533, avg_loss: 0.0003106363001279533\n",
      "[E: 53] loss: 7.444876246154308e-05, avg_loss: 7.444876246154308e-05\n",
      "[E: 54] loss: 0.001182482112199068, avg_loss: 0.001182482112199068\n",
      "[E: 55] loss: 0.00022411966347135603, avg_loss: 0.00022411966347135603\n",
      "[E: 56] loss: 0.0001100495719583705, avg_loss: 0.0001100495719583705\n",
      "[E: 57] loss: 0.006936539430171251, avg_loss: 0.006936539430171251\n",
      "[E: 58] loss: 5.4590334912063554e-05, avg_loss: 5.4590334912063554e-05\n",
      "[E: 59] loss: 6.09359958616551e-05, avg_loss: 6.09359958616551e-05\n",
      "Finished model vgg16_gan_3750_gan_augmented_rot_blur_sharp_s_42 evaluation!\n",
      "Test acc: 0.90625\n",
      "Saved testing logs.\n",
      "3750 GAN images:\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 3750}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.7703251242637634, avg_loss: 0.7703251242637634\n",
      "[E: 1] loss: 0.6021996736526489, avg_loss: 0.6021996736526489\n",
      "[E: 2] loss: 0.631190836429596, avg_loss: 0.631190836429596\n",
      "[E: 3] loss: 0.4079413414001465, avg_loss: 0.4079413414001465\n",
      "[E: 4] loss: 0.5737885236740112, avg_loss: 0.5737885236740112\n",
      "[E: 5] loss: 0.3507724106311798, avg_loss: 0.3507724106311798\n",
      "[E: 6] loss: 0.4521842896938324, avg_loss: 0.4521842896938324\n",
      "[E: 7] loss: 0.10993105918169022, avg_loss: 0.10993105918169022\n",
      "[E: 8] loss: 0.06163502484560013, avg_loss: 0.06163502484560013\n",
      "[E: 9] loss: 0.021785469725728035, avg_loss: 0.021785469725728035\n",
      "[E: 10] loss: 0.037274859845638275, avg_loss: 0.037274859845638275\n",
      "[E: 11] loss: 0.1303904801607132, avg_loss: 0.1303904801607132\n",
      "[E: 12] loss: 0.1082594096660614, avg_loss: 0.1082594096660614\n",
      "[E: 13] loss: 0.1528969556093216, avg_loss: 0.1528969556093216\n",
      "[E: 14] loss: 0.008255062624812126, avg_loss: 0.008255062624812126\n",
      "[E: 15] loss: 0.0023228719364851713, avg_loss: 0.0023228719364851713\n",
      "[E: 16] loss: 0.017381658777594566, avg_loss: 0.017381658777594566\n",
      "[E: 17] loss: 0.0036514021921902895, avg_loss: 0.0036514021921902895\n",
      "[E: 18] loss: 0.0060144150629639626, avg_loss: 0.0060144150629639626\n",
      "[E: 19] loss: 0.0072333854623138905, avg_loss: 0.0072333854623138905\n",
      "[E: 20] loss: 0.12255197763442993, avg_loss: 0.12255197763442993\n",
      "[E: 21] loss: 0.011000317521393299, avg_loss: 0.011000317521393299\n",
      "[E: 22] loss: 0.0021820140536874533, avg_loss: 0.0021820140536874533\n",
      "[E: 23] loss: 0.001092376303859055, avg_loss: 0.001092376303859055\n",
      "[E: 24] loss: 0.0002182557072956115, avg_loss: 0.0002182557072956115\n",
      "[E: 25] loss: 0.01718972995877266, avg_loss: 0.01718972995877266\n",
      "[E: 26] loss: 0.003022353630512953, avg_loss: 0.003022353630512953\n",
      "[E: 27] loss: 0.00043672401807270944, avg_loss: 0.00043672401807270944\n",
      "[E: 28] loss: 0.058334361761808395, avg_loss: 0.058334361761808395\n",
      "[E: 29] loss: 0.0011739687761291862, avg_loss: 0.0011739687761291862\n",
      "[E: 30] loss: 0.006648951210081577, avg_loss: 0.006648951210081577\n",
      "[E: 31] loss: 0.0020626888144761324, avg_loss: 0.0020626888144761324\n",
      "[E: 32] loss: 0.01916910521686077, avg_loss: 0.01916910521686077\n",
      "[E: 33] loss: 0.00010031874262494966, avg_loss: 0.00010031874262494966\n",
      "[E: 34] loss: 0.0006006152834743261, avg_loss: 0.0006006152834743261\n",
      "[E: 35] loss: 1.3983584722154774e-05, avg_loss: 1.3983584722154774e-05\n",
      "[E: 36] loss: 0.0003866326005663723, avg_loss: 0.0003866326005663723\n",
      "[E: 37] loss: 0.0003246611449867487, avg_loss: 0.0003246611449867487\n",
      "[E: 38] loss: 0.0019083417719230056, avg_loss: 0.0019083417719230056\n",
      "[E: 39] loss: 0.0001262326695723459, avg_loss: 0.0001262326695723459\n",
      "[E: 40] loss: 0.034655533730983734, avg_loss: 0.034655533730983734\n",
      "[E: 41] loss: 0.00046211396693252027, avg_loss: 0.00046211396693252027\n",
      "[E: 42] loss: 0.0016661447007209063, avg_loss: 0.0016661447007209063\n",
      "[E: 43] loss: 0.0023136360105127096, avg_loss: 0.0023136360105127096\n",
      "[E: 44] loss: 0.0023834812454879284, avg_loss: 0.0023834812454879284\n",
      "[E: 45] loss: 0.003618529997766018, avg_loss: 0.003618529997766018\n",
      "[E: 46] loss: 0.0009558073943480849, avg_loss: 0.0009558073943480849\n",
      "[E: 47] loss: 0.0005050250329077244, avg_loss: 0.0005050250329077244\n",
      "[E: 48] loss: 4.224874282954261e-05, avg_loss: 4.224874282954261e-05\n",
      "[E: 49] loss: 8.639662701170892e-05, avg_loss: 8.639662701170892e-05\n",
      "[E: 50] loss: 0.00037882651668041945, avg_loss: 0.00037882651668041945\n",
      "[E: 51] loss: 0.0015921477461233735, avg_loss: 0.0015921477461233735\n",
      "[E: 52] loss: 0.00012944760965183377, avg_loss: 0.00012944760965183377\n",
      "[E: 53] loss: 0.0016995308687910438, avg_loss: 0.0016995308687910438\n",
      "[E: 54] loss: 0.00023199437418952584, avg_loss: 0.00023199437418952584\n",
      "[E: 55] loss: 0.00017810794815886766, avg_loss: 0.00017810794815886766\n",
      "[E: 56] loss: 0.00028704345459118485, avg_loss: 0.00028704345459118485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E: 57] loss: 0.00031611204030923545, avg_loss: 0.00031611204030923545\n",
      "[E: 58] loss: 5.1863506087101996e-05, avg_loss: 5.1863506087101996e-05\n",
      "[E: 59] loss: 9.729502198752016e-05, avg_loss: 9.729502198752016e-05\n",
      "[E: 60] loss: 0.0009298360091634095, avg_loss: 0.0009298360091634095\n",
      "[E: 61] loss: 0.0002956134849227965, avg_loss: 0.0002956134849227965\n",
      "Finished model vgg16_gan_3750_gan_augmented_rot_blur_sharp_s_13 evaluation!\n",
      "Test acc: 0.9241071428571429\n",
      "Saved testing logs.\n",
      "3750 GAN images:\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 3750}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.7654435634613037, avg_loss: 0.7654435634613037\n",
      "[E: 1] loss: 1.3010098934173584, avg_loss: 1.3010098934173584\n",
      "[E: 2] loss: 0.677422285079956, avg_loss: 0.677422285079956\n",
      "[E: 5] loss: 0.26478883624076843, avg_loss: 0.26478883624076843\n",
      "[E: 6] loss: 0.32362455129623413, avg_loss: 0.32362455129623413\n",
      "[E: 7] loss: 0.036340054124593735, avg_loss: 0.036340054124593735\n",
      "[E: 8] loss: 0.17049632966518402, avg_loss: 0.17049632966518402\n",
      "[E: 9] loss: 0.10658060759305954, avg_loss: 0.10658060759305954\n",
      "[E: 10] loss: 0.04609508067369461, avg_loss: 0.04609508067369461\n",
      "[E: 11] loss: 0.44203853607177734, avg_loss: 0.44203853607177734\n",
      "[E: 12] loss: 0.019135992974042892, avg_loss: 0.019135992974042892\n",
      "[E: 13] loss: 0.031286031007766724, avg_loss: 0.031286031007766724\n",
      "[E: 14] loss: 0.009038691408932209, avg_loss: 0.009038691408932209\n",
      "[E: 15] loss: 0.03271663933992386, avg_loss: 0.03271663933992386\n",
      "[E: 16] loss: 0.17359046638011932, avg_loss: 0.17359046638011932\n",
      "[E: 17] loss: 0.007582605350762606, avg_loss: 0.007582605350762606\n",
      "[E: 18] loss: 0.11829132586717606, avg_loss: 0.11829132586717606\n",
      "[E: 19] loss: 0.00013322044105734676, avg_loss: 0.00013322044105734676\n",
      "[E: 20] loss: 0.009831874631345272, avg_loss: 0.009831874631345272\n",
      "[E: 21] loss: 0.0005346727557480335, avg_loss: 0.0005346727557480335\n",
      "[E: 22] loss: 0.00017201871378347278, avg_loss: 0.00017201871378347278\n",
      "[E: 23] loss: 0.01368860062211752, avg_loss: 0.01368860062211752\n",
      "[E: 24] loss: 0.010383330285549164, avg_loss: 0.010383330285549164\n",
      "[E: 25] loss: 0.0043617235496640205, avg_loss: 0.0043617235496640205\n",
      "[E: 26] loss: 0.0008154307142831385, avg_loss: 0.0008154307142831385\n",
      "[E: 27] loss: 0.1274021416902542, avg_loss: 0.1274021416902542\n",
      "[E: 28] loss: 0.11580508202314377, avg_loss: 0.11580508202314377\n",
      "[E: 29] loss: 0.03708791732788086, avg_loss: 0.03708791732788086\n",
      "[E: 30] loss: 0.05518949031829834, avg_loss: 0.05518949031829834\n",
      "[E: 31] loss: 0.0006402323488146067, avg_loss: 0.0006402323488146067\n",
      "[E: 32] loss: 0.030003422871232033, avg_loss: 0.030003422871232033\n",
      "[E: 33] loss: 0.003004697384312749, avg_loss: 0.003004697384312749\n",
      "[E: 34] loss: 0.0011787968687713146, avg_loss: 0.0011787968687713146\n",
      "[E: 35] loss: 0.001545281964354217, avg_loss: 0.001545281964354217\n",
      "Finished model vgg16_gan_3750_gan_augmented_rot_blur_sharp_s_25 evaluation!\n",
      "Test acc: 0.9077380952380952\n",
      "Saved testing logs.\n",
      "3750 GAN images:\n",
      "=> Loading checkpoint\n",
      "=> Loading checkpoint\n",
      "Dataset distribution: {'HCRP': 1868, 'NSCLC': 2812, 'LPET': 759, 'GAN': 3750}\n",
      "Starting model training...\n",
      "[E: 0] loss: 0.7195907831192017, avg_loss: 0.7195907831192017\n",
      "[E: 1] loss: 0.823009729385376, avg_loss: 0.823009729385376\n",
      "[E: 2] loss: 1.0211260318756104, avg_loss: 1.0211260318756104\n",
      "[E: 3] loss: 0.688538134098053, avg_loss: 0.688538134098053\n",
      "[E: 4] loss: 0.44690391421318054, avg_loss: 0.44690391421318054\n",
      "[E: 5] loss: 0.35737618803977966, avg_loss: 0.35737618803977966\n",
      "[E: 6] loss: 0.29082199931144714, avg_loss: 0.29082199931144714\n",
      "[E: 7] loss: 0.1064549908041954, avg_loss: 0.1064549908041954\n",
      "[E: 8] loss: 0.07273757457733154, avg_loss: 0.07273757457733154\n",
      "[E: 9] loss: 0.011819768697023392, avg_loss: 0.011819768697023392\n",
      "[E: 10] loss: 0.055845919996500015, avg_loss: 0.055845919996500015\n",
      "[E: 11] loss: 0.04438555985689163, avg_loss: 0.04438555985689163\n",
      "[E: 12] loss: 0.030977651476860046, avg_loss: 0.030977651476860046\n",
      "[E: 13] loss: 0.06603962182998657, avg_loss: 0.06603962182998657\n",
      "[E: 14] loss: 0.0031311889179050922, avg_loss: 0.0031311889179050922\n",
      "[E: 15] loss: 0.010594932362437248, avg_loss: 0.010594932362437248\n",
      "[E: 16] loss: 0.010720786638557911, avg_loss: 0.010720786638557911\n",
      "[E: 17] loss: 0.05081389471888542, avg_loss: 0.05081389471888542\n",
      "[E: 18] loss: 0.004034698009490967, avg_loss: 0.004034698009490967\n",
      "[E: 19] loss: 0.020815957337617874, avg_loss: 0.020815957337617874\n",
      "[E: 20] loss: 0.0014950335025787354, avg_loss: 0.0014950335025787354\n",
      "[E: 21] loss: 0.13892604410648346, avg_loss: 0.13892604410648346\n",
      "[E: 22] loss: 0.002240837784484029, avg_loss: 0.002240837784484029\n",
      "[E: 23] loss: 0.00021837993699591607, avg_loss: 0.00021837993699591607\n",
      "[E: 24] loss: 0.00033232796704396605, avg_loss: 0.00033232796704396605\n",
      "[E: 25] loss: 0.001396076288074255, avg_loss: 0.001396076288074255\n",
      "[E: 26] loss: 0.0029316332656890154, avg_loss: 0.0029316332656890154\n",
      "[E: 27] loss: 0.012832405976951122, avg_loss: 0.012832405976951122\n",
      "[E: 28] loss: 0.0008443492115475237, avg_loss: 0.0008443492115475237\n",
      "[E: 29] loss: 0.0019509182311594486, avg_loss: 0.0019509182311594486\n",
      "[E: 30] loss: 2.249962381029036e-05, avg_loss: 2.249962381029036e-05\n",
      "[E: 31] loss: 0.0002379693469265476, avg_loss: 0.0002379693469265476\n",
      "[E: 32] loss: 0.00019413535483181477, avg_loss: 0.00019413535483181477\n",
      "[E: 33] loss: 0.00024636267335154116, avg_loss: 0.00024636267335154116\n",
      "[E: 34] loss: 0.0025074726436287165, avg_loss: 0.0025074726436287165\n",
      "[E: 35] loss: 0.00023789715487509966, avg_loss: 0.00023789715487509966\n",
      "[E: 36] loss: 0.030640698969364166, avg_loss: 0.030640698969364166\n",
      "[E: 37] loss: 0.0010937092592939734, avg_loss: 0.0010937092592939734\n",
      "[E: 38] loss: 3.4579636121634394e-05, avg_loss: 3.4579636121634394e-05\n",
      "[E: 39] loss: 0.0010910126147791743, avg_loss: 0.0010910126147791743\n",
      "[E: 40] loss: 0.003427688730880618, avg_loss: 0.003427688730880618\n",
      "[E: 41] loss: 0.0003835102543234825, avg_loss: 0.0003835102543234825\n",
      "[E: 42] loss: 0.0005784800159744918, avg_loss: 0.0005784800159744918\n",
      "[E: 43] loss: 0.0013368397485464811, avg_loss: 0.0013368397485464811\n",
      "[E: 44] loss: 0.0004297179402783513, avg_loss: 0.0004297179402783513\n",
      "Finished model vgg16_gan_3750_gan_augmented_rot_blur_sharp_s_89 evaluation!\n",
      "Test acc: 0.9181547619047619\n",
      "Saved testing logs.\n"
     ]
    }
   ],
   "source": [
    "gen_adeno = \"generator_pggan_roi_adeno_epochs_50_alpha_0.75_aug_rot_blur_sharp.pth.tar\"\n",
    "gen_squamous = \"generator_pggan_roi_squamous_epochs_50_alpha_0.75_aug_rot_blur_sharp.pth.tar\"\n",
    "for no_gan_images in [3750]:\n",
    "    for SEED in [42,13, 25, 89]:\n",
    "        seed_everything(SEED)\n",
    "        print(f\"{no_gan_images} GAN images:\")\n",
    "        delete_gan_images()\n",
    "        generate_images(\n",
    "            gen_squamous, no_gan_images // 2, 'LUSC', \"/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/train/images/\")\n",
    "        generate_images(\n",
    "            gen_adeno, no_gan_images // 2, 'LUAD', \"/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/train/images/\")\n",
    "        train_loader, val_loader, test_loader = get_loaders(\n",
    "            train_dir = TRAIN_DIR,\n",
    "            val_dir = VAL_DIR,\n",
    "            test_dir = TEST_DIR,\n",
    "            transform = transform,\n",
    "        )\n",
    "        gan_model = 'gan_augmented_rot_blur_sharp'\n",
    "        model_name = train(train_loader, val_loader, gan=gan_model)\n",
    "        test(test_loader, model_name, gan_model=gan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bed1348b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>no_gan_generated_images</th>\n",
       "      <th>avg_acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>avg_precision</th>\n",
       "      <th>avg_recall</th>\n",
       "      <th>avg_f1-score</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>dropout</th>\n",
       "      <th>seed</th>\n",
       "      <th>gan_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vgg16_gan_0_dropout_0.2_opt_Adam</td>\n",
       "      <td>0</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.900178</td>\n",
       "      <td>0.888464</td>\n",
       "      <td>0.900178</td>\n",
       "      <td>0.892634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vgg16_gan_0_dropout_0.2_opt_SGD</td>\n",
       "      <td>0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.913324</td>\n",
       "      <td>0.912237</td>\n",
       "      <td>0.913324</td>\n",
       "      <td>0.912772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vgg16_gan_0_dropout_0.5_opt_SGD</td>\n",
       "      <td>0</td>\n",
       "      <td>0.922619</td>\n",
       "      <td>0.923574</td>\n",
       "      <td>0.916536</td>\n",
       "      <td>0.923574</td>\n",
       "      <td>0.919611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vgg16_gan_2500_dropout_0.5_opt_SGD</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.927919</td>\n",
       "      <td>0.921259</td>\n",
       "      <td>0.927919</td>\n",
       "      <td>0.924203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgg16_gan_5000_dropout_0.5_opt_SGD</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.898810</td>\n",
       "      <td>0.903966</td>\n",
       "      <td>0.891534</td>\n",
       "      <td>0.903966</td>\n",
       "      <td>0.895811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vgg16_gan_0_dropout_0.5_opt_SGD</td>\n",
       "      <td>0</td>\n",
       "      <td>0.903274</td>\n",
       "      <td>0.904969</td>\n",
       "      <td>0.896232</td>\n",
       "      <td>0.904969</td>\n",
       "      <td>0.899807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vgg16_gan_0_dropout_0.5_opt_SGD</td>\n",
       "      <td>0</td>\n",
       "      <td>0.909226</td>\n",
       "      <td>0.908534</td>\n",
       "      <td>0.903059</td>\n",
       "      <td>0.908534</td>\n",
       "      <td>0.905526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vgg16_gan_2500_dropout_0.5_opt_SGD_old_gan</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.907738</td>\n",
       "      <td>0.905971</td>\n",
       "      <td>0.901912</td>\n",
       "      <td>0.905971</td>\n",
       "      <td>0.903798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vgg16_gan_underfitting_test_1000_images</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758929</td>\n",
       "      <td>0.765374</td>\n",
       "      <td>0.753917</td>\n",
       "      <td>0.765374</td>\n",
       "      <td>0.754526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vgg16_gan_underfitting_test_2000_images</td>\n",
       "      <td>0</td>\n",
       "      <td>0.828869</td>\n",
       "      <td>0.824978</td>\n",
       "      <td>0.819920</td>\n",
       "      <td>0.824978</td>\n",
       "      <td>0.822109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vgg16_gan_underfitting_test_3000_images</td>\n",
       "      <td>0</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.861319</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.863956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vgg16_gan_underfitting_test_4000_images</td>\n",
       "      <td>0</td>\n",
       "      <td>0.883929</td>\n",
       "      <td>0.885027</td>\n",
       "      <td>0.876361</td>\n",
       "      <td>0.885027</td>\n",
       "      <td>0.879837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vgg16_gan_underfitting_test_5000_images</td>\n",
       "      <td>0</td>\n",
       "      <td>0.897321</td>\n",
       "      <td>0.900735</td>\n",
       "      <td>0.889964</td>\n",
       "      <td>0.900735</td>\n",
       "      <td>0.893997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vgg16_gan_0_dropout_0.5_opt_SGD_old_gan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.912202</td>\n",
       "      <td>0.913659</td>\n",
       "      <td>0.905530</td>\n",
       "      <td>0.913659</td>\n",
       "      <td>0.908950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vgg16_gan_2500_dropout_0.5_opt_SGD_old_gan</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.929813</td>\n",
       "      <td>0.922671</td>\n",
       "      <td>0.929813</td>\n",
       "      <td>0.925794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vgg16_gan_5000_dropout_0.5_opt_SGD_old_gan</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.921131</td>\n",
       "      <td>0.919675</td>\n",
       "      <td>0.915971</td>\n",
       "      <td>0.919675</td>\n",
       "      <td>0.917711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vgg16_gan_7500_dropout_0.5_opt_SGD_old_gan</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.899510</td>\n",
       "      <td>0.888446</td>\n",
       "      <td>0.899510</td>\n",
       "      <td>0.892519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vgg16_gan_10000_dropout_0.5_opt_SGD_old_gan</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.907738</td>\n",
       "      <td>0.909982</td>\n",
       "      <td>0.900755</td>\n",
       "      <td>0.909982</td>\n",
       "      <td>0.904486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vgg16_gan_0_dropout_0.5_opt_SGD_gan_75_epochs</td>\n",
       "      <td>0</td>\n",
       "      <td>0.912202</td>\n",
       "      <td>0.913659</td>\n",
       "      <td>0.905530</td>\n",
       "      <td>0.913659</td>\n",
       "      <td>0.908950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vgg16_gan_2500_dropout_0.5_opt_SGD_gan_75_epochs</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.922619</td>\n",
       "      <td>0.922237</td>\n",
       "      <td>0.917049</td>\n",
       "      <td>0.922237</td>\n",
       "      <td>0.919415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vgg16_gan_5000_dropout_0.5_opt_SGD_gan_75_epochs</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.907738</td>\n",
       "      <td>0.903966</td>\n",
       "      <td>0.902904</td>\n",
       "      <td>0.903966</td>\n",
       "      <td>0.903426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vgg16_gan_7500_dropout_0.5_opt_SGD_gan_75_epochs</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>0.892825</td>\n",
       "      <td>0.879643</td>\n",
       "      <td>0.892825</td>\n",
       "      <td>0.883791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vgg16_gan_10000_dropout_0.5_opt_SGD_gan_75_epochs</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.894345</td>\n",
       "      <td>0.892937</td>\n",
       "      <td>0.887671</td>\n",
       "      <td>0.892937</td>\n",
       "      <td>0.890038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>vgg16_gan_0_old_gan_s_13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.819940</td>\n",
       "      <td>0.814283</td>\n",
       "      <td>0.810777</td>\n",
       "      <td>0.814283</td>\n",
       "      <td>0.812368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>vgg16_gan_2500_old_gan_s_13</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.811012</td>\n",
       "      <td>0.808935</td>\n",
       "      <td>0.801700</td>\n",
       "      <td>0.808935</td>\n",
       "      <td>0.804461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>vgg16_gan_5000_old_gan_s_13</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.827206</td>\n",
       "      <td>0.812649</td>\n",
       "      <td>0.827206</td>\n",
       "      <td>0.806544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>vgg16_gan_0_old_gan_s_13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.909226</td>\n",
       "      <td>0.911876</td>\n",
       "      <td>0.902230</td>\n",
       "      <td>0.911876</td>\n",
       "      <td>0.906080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>vgg16_gan_2500_old_gan_s_13</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.909226</td>\n",
       "      <td>0.910539</td>\n",
       "      <td>0.902472</td>\n",
       "      <td>0.910539</td>\n",
       "      <td>0.905864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>vgg16_gan_5000_old_gan_s_13</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.925595</td>\n",
       "      <td>0.926693</td>\n",
       "      <td>0.919603</td>\n",
       "      <td>0.926693</td>\n",
       "      <td>0.922702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>vgg16_gan_0_old_gan_s_25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.906901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>vgg16_gan_2500_old_gan_s_25</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.919643</td>\n",
       "      <td>0.919118</td>\n",
       "      <td>0.913968</td>\n",
       "      <td>0.919118</td>\n",
       "      <td>0.916315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>vgg16_gan_5000_old_gan_s_25</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.913690</td>\n",
       "      <td>0.914884</td>\n",
       "      <td>0.907143</td>\n",
       "      <td>0.914884</td>\n",
       "      <td>0.910441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>vgg16_gan_0_old_gan_s_89</td>\n",
       "      <td>0</td>\n",
       "      <td>0.907738</td>\n",
       "      <td>0.910651</td>\n",
       "      <td>0.900667</td>\n",
       "      <td>0.910651</td>\n",
       "      <td>0.904594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>vgg16_gan_2500_old_gan_s_89</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.925914</td>\n",
       "      <td>0.922155</td>\n",
       "      <td>0.925914</td>\n",
       "      <td>0.923921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>vgg16_gan_5000_old_gan_s_89</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.915179</td>\n",
       "      <td>0.919452</td>\n",
       "      <td>0.908178</td>\n",
       "      <td>0.919452</td>\n",
       "      <td>0.912433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>vgg16_gan_0_gan_75_epochs_s_13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.909226</td>\n",
       "      <td>0.911876</td>\n",
       "      <td>0.902230</td>\n",
       "      <td>0.911876</td>\n",
       "      <td>0.906080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>vgg16_gan_2500_gan_75_epochs_s_13</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.933575</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.934664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>vgg16_gan_5000_gan_75_epochs_s_13</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.888393</td>\n",
       "      <td>0.886029</td>\n",
       "      <td>0.881724</td>\n",
       "      <td>0.886029</td>\n",
       "      <td>0.883699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>vgg16_gan_0_gan_75_epochs_s_25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.906901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>vgg16_gan_2500_gan_75_epochs_s_25</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.908422</td>\n",
       "      <td>0.905307</td>\n",
       "      <td>0.908422</td>\n",
       "      <td>0.906783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>vgg16_gan_5000_gan_75_epochs_s_25</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.909226</td>\n",
       "      <td>0.901849</td>\n",
       "      <td>0.907053</td>\n",
       "      <td>0.901849</td>\n",
       "      <td>0.904263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>vgg16_gan_0_gan_75_epochs_s_89</td>\n",
       "      <td>0</td>\n",
       "      <td>0.907738</td>\n",
       "      <td>0.910651</td>\n",
       "      <td>0.900667</td>\n",
       "      <td>0.910651</td>\n",
       "      <td>0.904594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>vgg16_gan_2500_gan_75_epochs_s_89</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.925595</td>\n",
       "      <td>0.922014</td>\n",
       "      <td>0.922014</td>\n",
       "      <td>0.922014</td>\n",
       "      <td>0.922014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>vgg16_gan_5000_gan_75_epochs_s_89</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.902406</td>\n",
       "      <td>0.894898</td>\n",
       "      <td>0.902406</td>\n",
       "      <td>0.898088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>vgg16_gan_bs_64</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.905919</td>\n",
       "      <td>0.899729</td>\n",
       "      <td>0.905919</td>\n",
       "      <td>0.902470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>vgg16_gan_bs_32</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.925245</td>\n",
       "      <td>0.922519</td>\n",
       "      <td>0.925245</td>\n",
       "      <td>0.923824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>vgg16_gan_0_gan_augmented_rot_blur_sharp_s_42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.598214</td>\n",
       "      <td>0.609626</td>\n",
       "      <td>0.604964</td>\n",
       "      <td>0.609626</td>\n",
       "      <td>0.595794</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42.0</td>\n",
       "      <td>gan_augmented_rot_blur_sharp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           model_name  \\\n",
       "0                    vgg16_gan_0_dropout_0.2_opt_Adam   \n",
       "1                     vgg16_gan_0_dropout_0.2_opt_SGD   \n",
       "2                     vgg16_gan_0_dropout_0.5_opt_SGD   \n",
       "3                  vgg16_gan_2500_dropout_0.5_opt_SGD   \n",
       "4                  vgg16_gan_5000_dropout_0.5_opt_SGD   \n",
       "5                     vgg16_gan_0_dropout_0.5_opt_SGD   \n",
       "6                     vgg16_gan_0_dropout_0.5_opt_SGD   \n",
       "7          vgg16_gan_2500_dropout_0.5_opt_SGD_old_gan   \n",
       "8             vgg16_gan_underfitting_test_1000_images   \n",
       "9             vgg16_gan_underfitting_test_2000_images   \n",
       "10            vgg16_gan_underfitting_test_3000_images   \n",
       "11            vgg16_gan_underfitting_test_4000_images   \n",
       "12            vgg16_gan_underfitting_test_5000_images   \n",
       "13            vgg16_gan_0_dropout_0.5_opt_SGD_old_gan   \n",
       "14         vgg16_gan_2500_dropout_0.5_opt_SGD_old_gan   \n",
       "15         vgg16_gan_5000_dropout_0.5_opt_SGD_old_gan   \n",
       "16         vgg16_gan_7500_dropout_0.5_opt_SGD_old_gan   \n",
       "17        vgg16_gan_10000_dropout_0.5_opt_SGD_old_gan   \n",
       "18      vgg16_gan_0_dropout_0.5_opt_SGD_gan_75_epochs   \n",
       "19   vgg16_gan_2500_dropout_0.5_opt_SGD_gan_75_epochs   \n",
       "20   vgg16_gan_5000_dropout_0.5_opt_SGD_gan_75_epochs   \n",
       "21   vgg16_gan_7500_dropout_0.5_opt_SGD_gan_75_epochs   \n",
       "22  vgg16_gan_10000_dropout_0.5_opt_SGD_gan_75_epochs   \n",
       "23                           vgg16_gan_0_old_gan_s_13   \n",
       "24                        vgg16_gan_2500_old_gan_s_13   \n",
       "25                        vgg16_gan_5000_old_gan_s_13   \n",
       "26                           vgg16_gan_0_old_gan_s_13   \n",
       "27                        vgg16_gan_2500_old_gan_s_13   \n",
       "28                        vgg16_gan_5000_old_gan_s_13   \n",
       "29                           vgg16_gan_0_old_gan_s_25   \n",
       "30                        vgg16_gan_2500_old_gan_s_25   \n",
       "31                        vgg16_gan_5000_old_gan_s_25   \n",
       "32                           vgg16_gan_0_old_gan_s_89   \n",
       "33                        vgg16_gan_2500_old_gan_s_89   \n",
       "34                        vgg16_gan_5000_old_gan_s_89   \n",
       "35                     vgg16_gan_0_gan_75_epochs_s_13   \n",
       "36                  vgg16_gan_2500_gan_75_epochs_s_13   \n",
       "37                  vgg16_gan_5000_gan_75_epochs_s_13   \n",
       "38                     vgg16_gan_0_gan_75_epochs_s_25   \n",
       "39                  vgg16_gan_2500_gan_75_epochs_s_25   \n",
       "40                  vgg16_gan_5000_gan_75_epochs_s_25   \n",
       "41                     vgg16_gan_0_gan_75_epochs_s_89   \n",
       "42                  vgg16_gan_2500_gan_75_epochs_s_89   \n",
       "43                  vgg16_gan_5000_gan_75_epochs_s_89   \n",
       "44                                    vgg16_gan_bs_64   \n",
       "45                                    vgg16_gan_bs_32   \n",
       "46      vgg16_gan_0_gan_augmented_rot_blur_sharp_s_42   \n",
       "\n",
       "    no_gan_generated_images   avg_acc       auc  avg_precision  avg_recall  \\\n",
       "0                         0  0.895833  0.900178       0.888464    0.900178   \n",
       "1                         0  0.916667  0.913324       0.912237    0.913324   \n",
       "2                         0  0.922619  0.923574       0.916536    0.923574   \n",
       "3                      2500  0.927083  0.927919       0.921259    0.927919   \n",
       "4                      5000  0.898810  0.903966       0.891534    0.903966   \n",
       "5                         0  0.903274  0.904969       0.896232    0.904969   \n",
       "6                         0  0.909226  0.908534       0.903059    0.908534   \n",
       "7                      2500  0.907738  0.905971       0.901912    0.905971   \n",
       "8                         0  0.758929  0.765374       0.753917    0.765374   \n",
       "9                         0  0.828869  0.824978       0.819920    0.824978   \n",
       "10                        0  0.869048  0.867424       0.861319    0.867424   \n",
       "11                        0  0.883929  0.885027       0.876361    0.885027   \n",
       "12                        0  0.897321  0.900735       0.889964    0.900735   \n",
       "13                        0  0.912202  0.913659       0.905530    0.913659   \n",
       "14                     2500  0.928571  0.929813       0.922671    0.929813   \n",
       "15                     5000  0.921131  0.919675       0.915971    0.919675   \n",
       "16                     7500  0.895833  0.899510       0.888446    0.899510   \n",
       "17                    10000  0.907738  0.909982       0.900755    0.909982   \n",
       "18                        0  0.912202  0.913659       0.905530    0.913659   \n",
       "19                     2500  0.922619  0.922237       0.917049    0.922237   \n",
       "20                     5000  0.907738  0.903966       0.902904    0.903966   \n",
       "21                     7500  0.886905  0.892825       0.879643    0.892825   \n",
       "22                    10000  0.894345  0.892937       0.887671    0.892937   \n",
       "23                        0  0.819940  0.814283       0.810777    0.814283   \n",
       "24                     2500  0.811012  0.808935       0.801700    0.808935   \n",
       "25                     5000  0.808036  0.827206       0.812649    0.827206   \n",
       "26                        0  0.909226  0.911876       0.902230    0.911876   \n",
       "27                     2500  0.909226  0.910539       0.902472    0.910539   \n",
       "28                     5000  0.925595  0.926693       0.919603    0.926693   \n",
       "29                        0  0.910714  0.909091       0.905000    0.909091   \n",
       "30                     2500  0.919643  0.919118       0.913968    0.919118   \n",
       "31                     5000  0.913690  0.914884       0.907143    0.914884   \n",
       "32                        0  0.907738  0.910651       0.900667    0.910651   \n",
       "33                     2500  0.927083  0.925914       0.922155    0.925914   \n",
       "34                     5000  0.915179  0.919452       0.908178    0.919452   \n",
       "35                        0  0.909226  0.911876       0.902230    0.911876   \n",
       "36                     2500  0.937500  0.935829       0.933575    0.935829   \n",
       "37                     5000  0.888393  0.886029       0.881724    0.886029   \n",
       "38                        0  0.910714  0.909091       0.905000    0.909091   \n",
       "39                     2500  0.910714  0.908422       0.905307    0.908422   \n",
       "40                     5000  0.909226  0.901849       0.907053    0.901849   \n",
       "41                        0  0.907738  0.910651       0.900667    0.910651   \n",
       "42                     2500  0.925595  0.922014       0.922014    0.922014   \n",
       "43                     5000  0.901786  0.902406       0.894898    0.902406   \n",
       "44                     5000  0.906250  0.905919       0.899729    0.905919   \n",
       "45                     5000  0.927083  0.925245       0.922519    0.925245   \n",
       "46                        0  0.598214  0.609626       0.604964    0.609626   \n",
       "\n",
       "    avg_f1-score  batch_size  learning_rate  epoch optimizer  dropout  seed  \\\n",
       "0       0.892634         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "1       0.912772         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "2       0.919611         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "3       0.924203         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "4       0.895811         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "5       0.899807         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "6       0.905526         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "7       0.903798         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "8       0.754526         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "9       0.822109         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "10      0.863956         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "11      0.879837         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "12      0.893997         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "13      0.908950         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "14      0.925794         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "15      0.917711         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "16      0.892519         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "17      0.904486         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "18      0.908950         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "19      0.919415         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "20      0.903426         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "21      0.883791         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "22      0.890038         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "23      0.812368         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "24      0.804461         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "25      0.806544         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "26      0.906080         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "27      0.905864         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "28      0.922702         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "29      0.906901         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "30      0.916315         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "31      0.910441         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "32      0.904594         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "33      0.923921         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "34      0.912433         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "35      0.906080         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "36      0.934664         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "37      0.883699         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "38      0.906901         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "39      0.906783         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "40      0.904263         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "41      0.904594         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "42      0.922014         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "43      0.898088         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "44      0.902470         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "45      0.923824         NaN            NaN    NaN       NaN      NaN   NaN   \n",
       "46      0.595794        32.0          0.001    1.0       SGD      0.5  42.0   \n",
       "\n",
       "                       gan_model  \n",
       "0                            NaN  \n",
       "1                            NaN  \n",
       "2                            NaN  \n",
       "3                            NaN  \n",
       "4                            NaN  \n",
       "5                            NaN  \n",
       "6                            NaN  \n",
       "7                            NaN  \n",
       "8                            NaN  \n",
       "9                            NaN  \n",
       "10                           NaN  \n",
       "11                           NaN  \n",
       "12                           NaN  \n",
       "13                           NaN  \n",
       "14                           NaN  \n",
       "15                           NaN  \n",
       "16                           NaN  \n",
       "17                           NaN  \n",
       "18                           NaN  \n",
       "19                           NaN  \n",
       "20                           NaN  \n",
       "21                           NaN  \n",
       "22                           NaN  \n",
       "23                           NaN  \n",
       "24                           NaN  \n",
       "25                           NaN  \n",
       "26                           NaN  \n",
       "27                           NaN  \n",
       "28                           NaN  \n",
       "29                           NaN  \n",
       "30                           NaN  \n",
       "31                           NaN  \n",
       "32                           NaN  \n",
       "33                           NaN  \n",
       "34                           NaN  \n",
       "35                           NaN  \n",
       "36                           NaN  \n",
       "37                           NaN  \n",
       "38                           NaN  \n",
       "39                           NaN  \n",
       "40                           NaN  \n",
       "41                           NaN  \n",
       "42                           NaN  \n",
       "43                           NaN  \n",
       "44                           NaN  \n",
       "45                           NaN  \n",
       "46  gan_augmented_rot_blur_sharp  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_log = pd.read_csv('vgg16_logging.csv')\n",
    "df_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef97dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_type_class = {0:'squamous' , 1:'adeno'}\n",
    "titles = []\n",
    "for true_label in incorrect_examples_true_labels:\n",
    "    pred_label = int(not true_label.item())\n",
    "    true_class = hist_type_class[true_label.item()]\n",
    "    pred_class = hist_type_class[pred_label]\n",
    "    titles.append(f\"pred: {pred_class} | label: {true_class}\")\n",
    "    \n",
    "# show_image_list(incorrect_examples_images, titles, num_cols=5, figsize=(16, 32), title_fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893f278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = 5\n",
    "list_images = incorrect_examples_images\n",
    "list_titles = titles\n",
    "figsize = (14, 30)\n",
    "\n",
    "num_images  = len(list_images)\n",
    "num_cols    = min(num_images, num_cols)\n",
    "num_rows    = int(num_images / num_cols) + (1 if num_images % num_cols != 0 else 0)\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "list_axes = list(axes.flat)\n",
    "for i in range(num_images):\n",
    "    img    = list_images[i]\n",
    "    title  = list_titles[i] if list_titles is not None else None\n",
    "\n",
    "    list_axes[i].imshow(img, cmap=None, vmin=-1, vmax=1)\n",
    "    list_axes[i].set_title(title, fontsize=12) \n",
    "\n",
    "    fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
