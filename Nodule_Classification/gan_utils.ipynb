{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20a1da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f36e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = [1, 1, 1, 1, 1 / 2, 1 / 4, 1 / 8, 1 / 16, 1 / 32]\n",
    "\n",
    "class WSConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Weight scaled Conv2d (Equalized Learning Rate)\n",
    "    Note that input is multiplied rather than changing weights\n",
    "    this will have the same result.\n",
    "\n",
    "    Inspired and looked at:\n",
    "    https://github.com/nvnbny/progressive_growing_of_gans/blob/master/modelUtils.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, gain=2\n",
    "    ):\n",
    "        super(WSConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.scale = (gain / (in_channels * (kernel_size ** 2))) ** 0.5\n",
    "        self.bias = self.conv.bias\n",
    "        self.conv.bias = None\n",
    "\n",
    "        # initialize conv layer\n",
    "        nn.init.normal_(self.conv.weight)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x * self.scale) + self.bias.view(1, self.bias.shape[0], 1, 1)\n",
    "\n",
    "\n",
    "class PixelNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PixelNorm, self).__init__()\n",
    "        self.epsilon = 1e-8\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x / torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + self.epsilon)\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_pixelnorm=True):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.use_pn = use_pixelnorm\n",
    "        self.conv1 = WSConv2d(in_channels, out_channels)\n",
    "        self.conv2 = WSConv2d(out_channels, out_channels)\n",
    "        self.leaky = nn.LeakyReLU(0.2)\n",
    "        self.pn = PixelNorm()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.leaky(self.conv1(x))\n",
    "        x = self.pn(x) if self.use_pn else x\n",
    "        x = self.leaky(self.conv2(x))\n",
    "        x = self.pn(x) if self.use_pn else x\n",
    "        return x\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, in_channels, img_channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # initial takes 1x1 -> 4x4\n",
    "        self.initial = nn.Sequential(\n",
    "            PixelNorm(),\n",
    "            nn.ConvTranspose2d(z_dim, in_channels, 4, 1, 0),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            WSConv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            PixelNorm(),\n",
    "        )\n",
    "\n",
    "        self.initial_rgb = WSConv2d(\n",
    "            in_channels, img_channels, kernel_size=1, stride=1, padding=0\n",
    "        )\n",
    "        self.prog_blocks, self.rgb_layers = (\n",
    "            nn.ModuleList([]),\n",
    "            nn.ModuleList([self.initial_rgb]),\n",
    "        )\n",
    "\n",
    "        for i in range(\n",
    "            len(factors) - 1\n",
    "        ):  # -1 to prevent index error because of factors[i+1]\n",
    "            conv_in_c = int(in_channels * factors[i])\n",
    "            conv_out_c = int(in_channels * factors[i + 1])\n",
    "            self.prog_blocks.append(ConvBlock(conv_in_c, conv_out_c))\n",
    "            self.rgb_layers.append(\n",
    "                WSConv2d(conv_out_c, img_channels, kernel_size=1, stride=1, padding=0)\n",
    "            )\n",
    "\n",
    "    def fade_in(self, alpha, upscaled, generated):\n",
    "        # alpha should be scalar within [0, 1], and upscale.shape == generated.shape\n",
    "        return torch.tanh(alpha * generated + (1 - alpha) * upscaled)\n",
    "\n",
    "    def forward(self, x, alpha, steps):\n",
    "        out = self.initial(x)\n",
    "\n",
    "        if steps == 0:\n",
    "            return self.initial_rgb(out)\n",
    "\n",
    "        for step in range(steps):\n",
    "            upscaled = F.interpolate(out, scale_factor=2, mode=\"nearest\")\n",
    "            out = self.prog_blocks[step](upscaled)\n",
    "\n",
    "        # The number of channels in upscale will stay the same, while\n",
    "        # out which has moved through prog_blocks might change. To ensure\n",
    "        # we can convert both to rgb we use different rgb_layers\n",
    "        # (steps-1) and steps for upscaled, out respectively\n",
    "        final_upscaled = self.rgb_layers[steps - 1](upscaled)\n",
    "        final_out = self.rgb_layers[steps](out)\n",
    "        return self.fade_in(alpha, final_upscaled, final_out)\n",
    "    \n",
    "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=\"cuda\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "    # If we don't do this then it will just have learning rate of old checkpoint\n",
    "    # and it will lead to many hours of debugging \\:\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fe812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(image):\n",
    "    min_val = MIN_HU_VALUE\n",
    "    max_val = MAX_HU_VALUE\n",
    "    return image * (max_val - min_val) + min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d663014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(\n",
    "    gen_checkpoint,\n",
    "    n,\n",
    "    hist_type,\n",
    "    path,\n",
    "    alpha = 1.0,\n",
    "    step=4,\n",
    "    z_dim=512,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    learning_rate=1e-3,\n",
    "    in_channels=512,\n",
    "    channels_img=1\n",
    "    ):\n",
    "    \n",
    "    gen = Generator(z_dim, in_channels, img_channels=channels_img).to(device)\n",
    "    opt_gen = optim.Adam(gen.parameters(), lr=learning_rate, betas=(0.0, 0.99))\n",
    "    load_checkpoint(gen_checkpoint, gen, opt_gen, learning_rate)\n",
    "    gen.train()\n",
    "    with torch.no_grad():\n",
    "        for i in range(n):\n",
    "            noise = torch.randn(1, z_dim, 1, 1).to(device)\n",
    "            fake_image = gen(noise, alpha, step)\n",
    "            fake_image = fake_image.cpu().numpy()\n",
    "            fake_image = fake_image * 0.5 + 0.5\n",
    "            fake_image = fake_image[0,0]\n",
    "            fake_image = denormalize(fake_image)\n",
    "            fake_image = np.around(fake_image)\n",
    "            image_file = f'GAN_{hist_type}_{str(i).zfill(4)}.dcm'\n",
    "            image_path = os.path.join(path, image_file)\n",
    "            write_dicom(fake_image, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f399aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete images\n",
    "def delete_gan_images():\n",
    "    directories = [\n",
    "        \"/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/train/images/\", \"/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/val/images/\",\n",
    "        \"/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/train/images/\", \"/Storage/PauloOctavioDir/splitted_folders/VGG-GAN/val/images/\"\n",
    "    ]\n",
    "\n",
    "    for directory in directories:\n",
    "        for file in os.listdir(directory):\n",
    "            if file.startswith('GAN'):\n",
    "                os.remove(os.path.join(directory, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "from pydicom.dataset import Dataset, FileDataset\n",
    "from pydicom.uid import ExplicitVRLittleEndian\n",
    "import pydicom._storage_sopclass_uids\n",
    "\n",
    "def write_dicom(image, filename, rescale_intercept=\"0\", rescale_slope=\"1\", pixel_spacing=r\"1\\1\"): \n",
    "    # ref: https://stackoverflow.com/questions/14350675/create-pydicom-file-from-numpy-array\n",
    "    if image.dtype != np.uint16:\n",
    "        image = image.astype(np.uint16)\n",
    "        \n",
    "    meta = pydicom.Dataset()\n",
    "    meta.MediaStorageSOPClassUID = pydicom._storage_sopclass_uids.CTImageStorage\n",
    "    meta.MediaStorageSOPInstanceUID = pydicom.uid.generate_uid()\n",
    "    meta.TransferSyntaxUID = pydicom.uid.ExplicitVRLittleEndian  \n",
    "\n",
    "    ds = Dataset()\n",
    "    ds.file_meta = meta\n",
    "\n",
    "    ds.is_little_endian = True\n",
    "    ds.is_implicit_VR = False\n",
    "\n",
    "    ds.SOPClassUID = pydicom._storage_sopclass_uids.CTImageStorage\n",
    "\n",
    "    ds.Modality = \"CT\"\n",
    "    ds.SeriesInstanceUID = pydicom.uid.generate_uid()\n",
    "    ds.StudyInstanceUID = pydicom.uid.generate_uid()\n",
    "    ds.FrameOfReferenceUID = pydicom.uid.generate_uid()\n",
    "\n",
    "    ds.BitsStored = 16\n",
    "    ds.BitsAllocated = 16\n",
    "    ds.SamplesPerPixel = 1\n",
    "    ds.HighBit = 15\n",
    "\n",
    "    ds.ImagesInAcquisition = \"1\"\n",
    "\n",
    "    ds.Rows = image.shape[0]\n",
    "    ds.Columns = image.shape[1]\n",
    "    ds.InstanceNumber = 1\n",
    "    \n",
    "    ds.RescaleIntercept = rescale_intercept\n",
    "    ds.RescaleSlope = rescale_slope\n",
    "    ds.PixelSpacing = pixel_spacing\n",
    "    ds.PhotometricInterpretation = \"MONOCHROME2\"\n",
    "    ds.PixelRepresentation = 1\n",
    "\n",
    "    pydicom.dataset.validate_file_meta(ds.file_meta, enforce_standard=True)\n",
    "        \n",
    "    ds.PixelData = image.tobytes()\n",
    "    ds.save_as(filename, write_like_original=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
